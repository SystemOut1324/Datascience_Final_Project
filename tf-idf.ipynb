{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execQuery(query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"postgres\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlesContent = execQuery(\"\"\"Select content\n",
    "from article\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection = psycopg2.connect(user = \"postgres\",\n",
    "#                                      password = \"root\",\n",
    "#                                      host = \"localhost\",\n",
    "#                                      port = \"5432\",\n",
    "#                                      database = \"postgres\")\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "filepath = '/home/daniel/OneDrive/KUuni/DataScience/Python/small.csv'\n",
    "#filepath = 'news_sample.csv' # <- overwrite for setup\n",
    "s = 250                    # desired sample size(seems to have slack ie. not exact)\n",
    "seed = 1                     # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_csv(filepath, index_col = [0]).sample(n=s, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content = df['content'].str.lower()\n",
    "series_content_tokens = df_content.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_content_tokens = series_content_tokens.explode()\n",
    "df_content_tokens = series_content_tokens.to_frame()\n",
    "df_content_tokens = df_content_tokens.reset_index().rename(columns={'index':'content_index'})\n",
    "series_content_tokens = df_content_tokens.groupby('content_index')['content'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "content_index  content     \n0              the             0.084715\n               .               0.040516\n               of              0.036832\n               to              0.029466\n               in              0.025783\n                                 ...   \n249            unacceptable    0.007752\n               wa              0.007752\n               wednesday       0.007752\n               will            0.007752\n               yangon          0.007752\nName: content, Length: 76994, dtype: float64"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "series_content_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "content_index       0         1         2    3    4    5         6    7    \\\ncontent                                                                     \n!              0.007366  0.008969       NaN  NaN  NaN  NaN  0.026316  NaN   \n#                   NaN       NaN       NaN  NaN  NaN  NaN       NaN  NaN   \n$              0.001842       NaN       NaN  NaN  NaN  NaN       NaN  NaN   \n%                   NaN  0.004484       NaN  NaN  NaN  NaN       NaN  NaN   \n&                   NaN  0.004484  0.001912  NaN  NaN  NaN       NaN  NaN   \n\ncontent_index       8    9    ...       240  241       242  243  244  \\\ncontent                       ...                                      \n!              0.003388  NaN  ...  0.004484  NaN       NaN  NaN  NaN   \n#                   NaN  NaN  ...       NaN  NaN       NaN  NaN  NaN   \n$              0.014037  NaN  ...       NaN  NaN  0.003247  NaN  NaN   \n%              0.003872  NaN  ...       NaN  NaN       NaN  NaN  NaN   \n&              0.000968  NaN  ...  0.002242  NaN       NaN  NaN  NaN   \n\ncontent_index       245       246  247       248  249  \ncontent                                                \n!              0.001922  0.002985  NaN  0.002016  NaN  \n#                   NaN       NaN  NaN       NaN  NaN  \n$              0.001281       NaN  NaN       NaN  NaN  \n%              0.004484       NaN  NaN       NaN  NaN  \n&              0.000641  0.002985  NaN       NaN  NaN  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>content_index</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>240</th>\n      <th>241</th>\n      <th>242</th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n    </tr>\n    <tr>\n      <th>content</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>!</th>\n      <td>0.007366</td>\n      <td>0.008969</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.026316</td>\n      <td>NaN</td>\n      <td>0.003388</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.004484</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.001922</td>\n      <td>0.002985</td>\n      <td>NaN</td>\n      <td>0.002016</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>#</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>$</th>\n      <td>0.001842</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.014037</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.003247</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.001281</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>%</th>\n      <td>NaN</td>\n      <td>0.004484</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.003872</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.004484</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>&amp;</th>\n      <td>NaN</td>\n      <td>0.004484</td>\n      <td>0.001912</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000968</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.002242</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000641</td>\n      <td>0.002985</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 250 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# create TF\n",
    "TF = series_content_tokens.unstack(level=0)\n",
    "TF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0007521289603870707"
     },
     "metadata": {},
     "execution_count": 341
    }
   ],
   "source": [
    "a = TF[TF > 0] / np.log(1 + len(TF))\n",
    "a.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9c3c2739340c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorpus_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "corpus_index = [n for n in corpus]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "This        3\nis          2\nfirst       1\nsecond      1\nthe         2\nsentence    2\nthird       1\ndtype: int64\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_1 = pd.DataFrame({'sent': \n",
    "                    ['This This is is first', \n",
    "                     'This is the second sentence',\n",
    "                     'This the third sentence']})\n",
    "\n",
    "# Tokenize and generate count vectors\n",
    "word_vec = df_1.sent.str.split().apply(pd.value_counts).fillna(0)\n",
    "\n",
    "# Compute term frequencies\n",
    "tf = word_vec.divide(np.sum(word_vec, axis='columns'), axis='index')\n",
    "\n",
    "# Compute inverse document frequencies\n",
    "idf = np.log(len(tf) / word_vec[word_vec > 0].count()) \n",
    "\n",
    "# Compute TF-IDF vectors\n",
    "tfidf = np.multiply(tf, idf.to_frame().T)\n",
    "\n",
    "print(word_vec[word_vec > 0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   This is the first sentence  This is the second sentence  \\\n0                        26.0                          0.0   \n1                         0.0                         27.0   \n2                         0.0                          0.0   \n\n   This is the third sentence  \n0                         0.0  \n1                         0.0  \n2                        26.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>This is the first sentence</th>\n      <th>This is the second sentence</th>\n      <th>This is the third sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>26.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df = pd.DataFrame({'docId': [1,2,3], \n",
    "               'sent': ['This is the first sentence', \n",
    "                        'This is the second sentence',\n",
    "                        'This is the third sentence']})\n",
    "\n",
    "# use 'value_counts' to get counts of items in list\n",
    "tf = df.sent.apply(pd.value_counts).fillna(0) \n",
    "# tf = df.sent.str.split().apply(pd.value_counts).fillna(0)\n",
    "\n",
    "# add one to numerator and denominator just incase a term isn't in any document\n",
    "# maximum value is log(N) and minimum value is zero\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "scipy.sparse.csr.csr_matrix"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'docId': [1,2,3], \n",
    "               'sent': ['This is the first sentence','This is the second sentence', 'This is the third sentence']})\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df['sent'])\n",
    " \n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('DS': conda)",
   "language": "python",
   "name": "python37764bitdsconda217f41063fe24cf89ccdf8aa73f962cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}