{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries needed \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# libraries we might not need\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the following code\n",
    "to use the whole document you only need one file specified by filepath for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 15 ms\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Unnamed: 0.1     id                  domain       type  \\\n67             67  11593  washingtonexaminer.com  political   \n249           249  39558         www.newsmax.com        NaN   \n230           230  37351       beforeitsnews.com       fake   \n161           161  25191       beforeitsnews.com       fake   \n91             91  15468       beforeitsnews.com       fake   \n\n                                                   url  \\\n67   http://www.washingtonexaminer.com/us-support-f...   \n249  https://www.newsmax.com/newsfront/bill-clinton...   \n230  http://beforeitsnews.com/alternative/2018/01/t...   \n161  http://beforeitsnews.com/health/2017/04/audio-...   \n91   http://beforeitsnews.com/science-and-technolog...   \n\n                                               content  \\\n67   The United States has slashed its contribution...   \n249  Former U.S. President Bill Clinton on Monday c...   \n230  The Real Story Behind Marijuana Prohibition\\r\\...   \n161  Audio Sensors Market Analysis by Current Indus...   \n91   Headline: Bitcoin & Blockchain Searches Exceed...   \n\n                     scraped_at                 inserted_at  \\\n67   2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n249  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n230  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n161  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n91   2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n\n                     updated_at  \\\n67   2018-02-02 01:19:41.756664   \n249  2018-02-02 01:19:41.756664   \n230  2018-02-02 01:19:41.756664   \n161  2018-02-02 01:19:41.756664   \n91   2018-02-02 01:19:41.756664   \n\n                                                 title            authors  \\\n67        US support for UNRWA has gone on long enough      Michael Rubin   \n249  Bill Clinton Calls for Release of Reuters Jour...                NaN   \n230        The Real Story Behind Marijuana Prohibition  The Daily Sheeple   \n161  Audio Sensors Market Analysis by Current Indus...                NaN   \n91   Yawning — Why Is It So Contagious and Why Shou...      Alton Parrish   \n\n     keywords                                      meta_keywords  \\\n67        NaN  ['Blog Contributors', 'Refugees', 'Palestinian...   \n249       NaN  ['bill clinton', 'myanmar', 'calls', 'release'...   \n230       NaN                                               ['']   \n161       NaN                                               ['']   \n91        NaN                                               ['']   \n\n                                      meta_description  \\\n67   When the U.N. created UNRWA, it was meant to b...   \n249  Former U.S. President Bill Clinton Calls for R...   \n230                                                NaN   \n161                                                NaN   \n91                                                 NaN   \n\n                                                  tags  summary content_tokens  \n67                                                 NaN      NaN             []  \n249  Donald Trump, Russia, Trump Administration, Gu...      NaN             []  \n230                                                NaN      NaN             []  \n161                                                NaN      NaN             []  \n91                                                 NaN      NaN             []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>id</th>\n      <th>domain</th>\n      <th>type</th>\n      <th>url</th>\n      <th>content</th>\n      <th>scraped_at</th>\n      <th>inserted_at</th>\n      <th>updated_at</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>keywords</th>\n      <th>meta_keywords</th>\n      <th>meta_description</th>\n      <th>tags</th>\n      <th>summary</th>\n      <th>content_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67</th>\n      <td>67</td>\n      <td>11593</td>\n      <td>washingtonexaminer.com</td>\n      <td>political</td>\n      <td>http://www.washingtonexaminer.com/us-support-f...</td>\n      <td>The United States has slashed its contribution...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>US support for UNRWA has gone on long enough</td>\n      <td>Michael Rubin</td>\n      <td>NaN</td>\n      <td>['Blog Contributors', 'Refugees', 'Palestinian...</td>\n      <td>When the U.N. created UNRWA, it was meant to b...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>249</td>\n      <td>39558</td>\n      <td>www.newsmax.com</td>\n      <td>NaN</td>\n      <td>https://www.newsmax.com/newsfront/bill-clinton...</td>\n      <td>Former U.S. President Bill Clinton on Monday c...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Bill Clinton Calls for Release of Reuters Jour...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['bill clinton', 'myanmar', 'calls', 'release'...</td>\n      <td>Former U.S. President Bill Clinton Calls for R...</td>\n      <td>Donald Trump, Russia, Trump Administration, Gu...</td>\n      <td>NaN</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>230</td>\n      <td>37351</td>\n      <td>beforeitsnews.com</td>\n      <td>fake</td>\n      <td>http://beforeitsnews.com/alternative/2018/01/t...</td>\n      <td>The Real Story Behind Marijuana Prohibition\\r\\...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>The Real Story Behind Marijuana Prohibition</td>\n      <td>The Daily Sheeple</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>161</td>\n      <td>25191</td>\n      <td>beforeitsnews.com</td>\n      <td>fake</td>\n      <td>http://beforeitsnews.com/health/2017/04/audio-...</td>\n      <td>Audio Sensors Market Analysis by Current Indus...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Audio Sensors Market Analysis by Current Indus...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>91</td>\n      <td>15468</td>\n      <td>beforeitsnews.com</td>\n      <td>fake</td>\n      <td>http://beforeitsnews.com/science-and-technolog...</td>\n      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Yawning — Why Is It So Contagious and Why Shou...</td>\n      <td>Alton Parrish</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "%%time\n",
    "# imports a random sample of size s from csv-file as a pandas dataframe\n",
    "# pandas using python 3.X uses utf-8 encoding\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random)\n",
    "filepath = '../Data_sample/FakeNewsCorpus_250.csv'\n",
    "#filepath = 'news_sample.csv' # <- overwrite for setup\n",
    "s = 250                    # desired sample size(seems to have slack ie. not exact)\n",
    "seed = 1                     # seed used by Pseudorandom number generator\n",
    "\n",
    "# init dataframe with specified values\n",
    "df = pd.read_csv(filepath, index_col = [0]).sample(n=s, random_state=seed)\n",
    "\n",
    "# visual output\n",
    "#print(df.shape, '<- size of dataframe \\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], errors = 'coerce', downcast = 'integer')\n",
    "df.drop_duplicates(subset = 'id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(250, 16)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df = df.dropna(subset=['id']).set_index('id')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning for values out of bounds of DataBase requirements etc.\n",
    "df.index = df.index.astype(int)\n",
    "longAuthors = df[df['authors'].str.len() > 255].index\n",
    "df.drop(longAuthors, inplace = True)\n",
    "longTags = df[df['tags'].str.len() > 1000].drop_duplicates(subset = 'tags', keep = 'first').index\n",
    "df.drop(longTags, inplace = True)\n",
    "longMetaD = df[df['meta_description'].str.len() > 10000].index\n",
    "df.drop(longMetaD, inplace = True)\n",
    "df['authors'] = df['authors'].replace(np.nan, 'NoAuthor', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 28 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "regexEmail = r\"[a-zA-Z_-]+@[a-zA-Z_-]+(\\.[a-zA-Z]{2,4}){1,3}\"\n",
    "df.content = df.content.replace(to_replace=regexEmail, value='<EMAIL>', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 122 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "regexURL= r\"(?:https?:\\/\\/)?(?:www\\.)?([^@\\s]+\\.[a-zA-Z]{2,4})[^\\s]*\"\n",
    "df.content = df.content.replace(to_replace=regexURL, value='<URL>', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexDoubleSpace = r\"(\\s{2,})|\\n\"\n",
    "df.content = df.content.replace(to_replace=regexDoubleSpace, value=' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexDate = r\"(((19[7-9]\\d|20\\d{2})|(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|(nov|dec)(?:ember)?)|(([12][0-9])|(3[01])|(0?[1-9])))[\\/. \\-,\\n]){2,3}\"\n",
    "df.content = df.content.replace(to_replace=regexDate, value='<DATE>', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 16 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "regexNum = r\"(\\s)\\$?(?:[\\d,.-])+\"\n",
    "df.content = df.content.replace(to_replace=regexNum, value='<NUM>', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data-tables: [name]-uniq / relational-tables: [name]_in\n",
    "creating csv-files for database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to save all csv-files\n",
    "path = '../Data_git_ignore/clean_csv/'\n",
    "\n",
    "# create temporary dataframe and use article id as index \n",
    "out_df = pd.DataFrame({'id':df.index})\n",
    "out_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### types_uniq - data-table ###\n",
    "type_array = df.type.unique() # get array of unique types\n",
    "type_df = pd.DataFrame({'id': np.arange(type_array.size), 'name':type_array})\n",
    "\n",
    "# write file and free memory\n",
    "type_df.to_csv(path + 'type.csv', index=False, header=True)\n",
    "#del type_array\n",
    "#del type_df # tmp delete later\n",
    "\n",
    "# create dict with type_name as key - [swap type with type_id]\n",
    "type_name_as_key_df = type_df.set_index('name')\n",
    "type_dict = type_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace type with tag id and create new column\n",
    "type_id = np.array([type_dict[key] for key in df['type'].to_numpy()])\n",
    "df['type_id'] =type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "tags_series_of_lists = df.tags.dropna().str.split(', ') # -> ', ' not ','\n",
    "\n",
    "if not 'tags' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'tags', value = tags_series_of_lists)\n",
    "\n",
    "# flattern tags_series_of_lists to a set(ie. unique values only)\n",
    "tags_list = list(set([item for sublist in tags_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "tags_df = pd.DataFrame({'id': np.arange(len(tags_list)), 'name':tags_list})\n",
    "\n",
    "# write file and free memory\n",
    "tags_df.to_csv(path + 'tags.csv', index=False, header=True)\n",
    "del tags_series_of_lists\n",
    "del tags_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### tags_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and tags in a article (for all articles)\n",
    "articles_id_tags_name_pairs_df = out_df.tags.dropna().explode().drop_duplicates(keep = 'first')\n",
    "\n",
    "# split tags_name and articles_id\n",
    "articles_id_array = articles_id_tags_name_pairs_df.index.to_numpy()\n",
    "tags_name_array = articles_id_tags_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap tags with tags_id]\n",
    "tags_name_as_key_df = tags_df.set_index('name')\n",
    "tags_dict = tags_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace tags with tag id\n",
    "tags_id = np.array([tags_dict[key] for key in tags_name_array])\n",
    "\n",
    "# create dataframe\n",
    "tags_in_df = pd.DataFrame(data=articles_id_array, index=tags_id, columns=['article_id'])\n",
    "tags_in_df.index.name='tags_id'\n",
    "\n",
    "# write file and free memory\n",
    "tags_in_df.to_csv(path + 'tags_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### authors-uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "authors_series_of_lists = df.authors.str.split(',') # -> ',' not ', '\n",
    "\n",
    "if not 'authors' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'authors', value = authors_series_of_lists)\n",
    "\n",
    "# flattern authors_series_of_lists to a set(ie. unique values only)\n",
    "authors_list = list(set([item for sublist in authors_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "authors_df = pd.DataFrame({'id': np.arange(len(authors_list)), 'name':authors_list})\n",
    "\n",
    "# write file and free memory\n",
    "authors_df.to_csv(path + 'authors.csv', index=False, header=True)\n",
    "#del authors_series_of_lists\n",
    "#del authors_list\n",
    "#del authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors_in - relational-table ###\n",
    "#for i in out_df.index:\n",
    "    #out_df.author[i] = list(set(out_df.authors[i]))\n",
    "# get all pairs of article_id and authors in a article (for all articles)\n",
    "articles_id_authors_name_pairs_df = out_df.authors.dropna().explode()\n",
    "\n",
    "# split authors_name and articles_id\n",
    "articles_id_array = articles_id_authors_name_pairs_df.index.to_numpy()\n",
    "authors_name_array = articles_id_authors_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap authors with authors_id]\n",
    "authors_name_as_key_df = authors_df.set_index('name')\n",
    "authors_dict = authors_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace authors with tag id\n",
    "authors_id = np.array([authors_dict[key] for key in authors_name_array])\n",
    "\n",
    "# create dataframe\n",
    "authors_in_df = pd.DataFrame(data=articles_id_array, index=authors_id, columns=['article_id'])\n",
    "authors_in_df.index.name='authors_id'\n",
    "\n",
    "# write file and free memory\n",
    "authors_in_df.to_csv(path + 'authors_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### domains-uniq - data-table ###\n",
    "domain_array = df.domain.unique() # get array of unique domains\n",
    "domain_df = pd.DataFrame({'id': np.arange(domain_array.size), 'name':domain_array})\n",
    "\n",
    "# write file and free memory\n",
    "domain_df.to_csv(path + 'domain_name.csv', index=False, header=True)\n",
    "#del domain_array\n",
    "#del domain_df\n",
    "\n",
    "# create dict with domain_name as key - [swap domain with domain_id]\n",
    "domain_name_as_key_df = domain_df.set_index('name')\n",
    "domain_dict = domain_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace domain with tag id and create new column\n",
    "domain_id = np.array([domain_dict[key] for key in df['domain'].to_numpy()])\n",
    "df['domain_id'] =domain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_uniq - data-table ###\n",
    "\n",
    "# use regex to remove string-padding\n",
    "regex = r\" *['\\\"\\[\\]]+\"\n",
    "meta_keywords_series = df.meta_keywords.replace(to_replace=regex, value='', regex=True).str.split(',')\n",
    "#meta_keywords_series = meta_keywords_series.replace(r'', np.NaN)\n",
    "\n",
    "if not 'meta_keywords' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'meta_keywords', value = meta_keywords_series)\n",
    "\n",
    "# create array of unique\n",
    "meta_keywords_set = meta_keywords_series.explode().unique()\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_df = pd.DataFrame({'id': np.arange(len(meta_keywords_set)), 'name':meta_keywords_set})\n",
    "\n",
    "# write file and free memory\n",
    "meta_keywords_df.to_csv(path + 'meta_keywords.csv', index=False, header=True)\n",
    "#del meta_keywords_series\n",
    "#del meta_keywords_set\n",
    "#del meta_keywords_list\n",
    "#del meta_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and meta_keywords in a article (for all articles)\n",
    "articles_id_meta_keywords_name_pairs_df = out_df.meta_keywords.dropna().explode()\n",
    "\n",
    "# split meta_keywords_name and articles_id\n",
    "articles_id_array = articles_id_meta_keywords_name_pairs_df.index.to_numpy()\n",
    "meta_keywords_name_array = articles_id_meta_keywords_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap meta_keywords with meta_keywords_id]\n",
    "meta_keywords_name_as_key_df = meta_keywords_df.set_index('name')\n",
    "meta_keywords_dict = meta_keywords_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace meta_keywords with tag id\n",
    "meta_keywords_id = np.array([meta_keywords_dict[key] for key in meta_keywords_name_array])\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_in_df = pd.DataFrame(data=articles_id_array, index=meta_keywords_id, columns=['article_id'])\n",
    "\n",
    "meta_keywords_in_df.index.name='meta_keywords_id'\n",
    "meta_keywords_in_df.reset_index(inplace = True)\n",
    "meta_keywords_in_df.drop_duplicates(subset = ['meta_keywords_id', 'article_id'], keep = 'first', inplace = True)\n",
    "# write file and free memory\n",
    "meta_keywords_in_df.to_csv(path + 'meta_keywords_in.csv', index=False, header=True)\n",
    "#meta_keywords_in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### article clean ###\n",
    "\n",
    "df[['domain_id', 'type_id', \"url\", \"content\", \"title\", \"meta_description\", \"scraped_at\",  \"updated_at\", \"inserted_at\"]].to_csv(path + 'article.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 content\nid                                                      \n11593  The United States has slashed its contribution...\n39558  Former U.S. President Bill Clinton on Monday c...\n37351  The Real Story Behind Marijuana Prohibition % ...\n25191  Audio Sensors Market Analysis by Current Indus...\n15468  Headline: Bitcoin & Blockchain Searches Exceed...\n...                                                  ...\n22530  Headline: Bitcoin & Blockchain Searches Exceed...\n12071  A Weird Week Draws To A Close Headline: Bitcoi...\n22583  How To Easily Understand The Difference Betwee...\n37842  ERROR Main Error Mesage Here More detailed mes...\n6045   Greg Hunter: Big Banks in Big Trouble, Syria/N...\n\n[247 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11593</th>\n      <td>The United States has slashed its contribution...</td>\n    </tr>\n    <tr>\n      <th>39558</th>\n      <td>Former U.S. President Bill Clinton on Monday c...</td>\n    </tr>\n    <tr>\n      <th>37351</th>\n      <td>The Real Story Behind Marijuana Prohibition % ...</td>\n    </tr>\n    <tr>\n      <th>25191</th>\n      <td>Audio Sensors Market Analysis by Current Indus...</td>\n    </tr>\n    <tr>\n      <th>15468</th>\n      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22530</th>\n      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n    </tr>\n    <tr>\n      <th>12071</th>\n      <td>A Weird Week Draws To A Close Headline: Bitcoi...</td>\n    </tr>\n    <tr>\n      <th>22583</th>\n      <td>How To Easily Understand The Difference Betwee...</td>\n    </tr>\n    <tr>\n      <th>37842</th>\n      <td>ERROR Main Error Mesage Here More detailed mes...</td>\n    </tr>\n    <tr>\n      <th>6045</th>\n      <td>Greg Hunter: Big Banks in Big Trouble, Syria/N...</td>\n    </tr>\n  </tbody>\n</table>\n<p>247 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df[['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['type_id', 'content']].to_csv('d:/Personal/Desktop/downloads-tmp/' + 'learning-clean.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0.1\ndomain\ntype\nurl\ncontent\nscraped_at\ninserted_at\nupdated_at\ntitle\nauthors\nkeywords\nmeta_keywords\nmeta_description\ntags\nsummary\ncontent_tokens\ntype_id\ndomain_id\n"
    }
   ],
   "source": [
    "for col in df.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}