{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  id              domain   type  \\\n0  2       express.co.uk  rumor   \n1  6  barenakedislam.com   hate   \n2  7  barenakedislam.com   hate   \n3  8  barenakedislam.com   hate   \n4  9  barenakedislam.com   hate   \n\n                                                 url  \\\n0  https://www.express.co.uk/news/science/738402/...   \n1  http://barenakedislam.com/category/donald-trum...   \n2  http://barenakedislam.com/category/donald-trum...   \n3  http://barenakedislam.com/2017/12/24/more-winn...   \n4  http://barenakedislam.com/2017/12/25/oh-trump-...   \n\n                                             content  \\\n0  Life is an illusion, at least on a quantum lev...   \n1  Unfortunately, he hasn’t yet attacked her for ...   \n2  The Los Angeles Police Department has been den...   \n3  The White House has decided to quietly withdra...   \n4  “The time has come to cut off the tongues of t...   \n\n                   scraped_at                 inserted_at  \\\n0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n\n                   updated_at  \\\n0  2018-02-02 01:19:41.756664   \n1  2018-02-02 01:19:41.756664   \n2  2018-02-02 01:19:41.756664   \n3  2018-02-02 01:19:41.756664   \n4  2018-02-02 01:19:41.756664   \n\n                                               title  \\\n0  Is life an ILLUSION? Researchers prove 'realit...   \n1                                       Donald Trump   \n2                                       Donald Trump   \n3  MORE WINNING! Israeli intelligence source, DEB...   \n4  “Oh, Trump, you coward, you just wait, we will...   \n\n                                             authors  keywords meta_keywords  \\\n0                                        Sean Martin       NaN          ['']   \n1  Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN          ['']   \n2  Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN          ['']   \n3  Cleavis Nowell, Cleavisnowell, Clarence J. Fei...       NaN          ['']   \n4  F.N. Lehner, Don Spilman, Clarence J. Feinour,...       NaN          ['']   \n\n                                    meta_description tags  summary  source  \\\n0  THE UNIVERSE ceases to exist when we are not l...  NaN      NaN     NaN   \n1                                                NaN  NaN      NaN     NaN   \n2                                                NaN  NaN      NaN     NaN   \n3                                                NaN  NaN      NaN     NaN   \n4                                                NaN  NaN      NaN     NaN   \n\n   type_id  \n0        8  \n1        4  \n2        4  \n3        4  \n4        4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>domain</th>\n      <th>type</th>\n      <th>url</th>\n      <th>content</th>\n      <th>scraped_at</th>\n      <th>inserted_at</th>\n      <th>updated_at</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>keywords</th>\n      <th>meta_keywords</th>\n      <th>meta_description</th>\n      <th>tags</th>\n      <th>summary</th>\n      <th>source</th>\n      <th>type_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>express.co.uk</td>\n      <td>rumor</td>\n      <td>https://www.express.co.uk/news/science/738402/...</td>\n      <td>Life is an illusion, at least on a quantum lev...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Is life an ILLUSION? Researchers prove 'realit...</td>\n      <td>Sean Martin</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>THE UNIVERSE ceases to exist when we are not l...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>6</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/category/donald-trum...</td>\n      <td>Unfortunately, he hasn’t yet attacked her for ...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Donald Trump</td>\n      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/category/donald-trum...</td>\n      <td>The Los Angeles Police Department has been den...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Donald Trump</td>\n      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>8</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/2017/12/24/more-winn...</td>\n      <td>The White House has decided to quietly withdra...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>MORE WINNING! Israeli intelligence source, DEB...</td>\n      <td>Cleavis Nowell, Cleavisnowell, Clarence J. Fei...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>9</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/2017/12/25/oh-trump-...</td>\n      <td>“The time has come to cut off the tongues of t...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>“Oh, Trump, you coward, you just wait, we will...</td>\n      <td>F.N. Lehner, Don Spilman, Clarence J. Feinour,...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# importing and creating df (has to have type_id)\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random)\n",
    "#filepath = '../Data_sample/FakeNewsCorpus_250.csv' # 250 rows of FakeNewsCorpus\n",
    "filepath = '/Users/Master/Documents/KU/2.Semester/Datascience/1mioraw.csv'       # 1 mil rows raw\n",
    "#s = 1000000                                            # desired sample size\n",
    "#seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_csv(filepath, index_col = [0])\n",
    "df[\"content\"] = df[\"content\"].astype(str)\n",
    "# create type_id\n",
    "df['type_id'] = df.groupby(['type']).ngroup()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933],\n      dtype='object', length=1000000)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df['id'] = pd.to_numeric(df['id'], errors = 'coerce', downcast = 'integer')\n",
    "df.dropna(subset=['id'], inplace = True)\n",
    "#df.drop_duplicates(subset = 'content', inplace = True)\n",
    "df.drop_duplicates(subset = 'id', inplace = True)\n",
    "df.id = df.id.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source, type_id]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>domain</th>\n      <th>type</th>\n      <th>url</th>\n      <th>content</th>\n      <th>scraped_at</th>\n      <th>inserted_at</th>\n      <th>updated_at</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>keywords</th>\n      <th>meta_keywords</th>\n      <th>meta_description</th>\n      <th>tags</th>\n      <th>summary</th>\n      <th>source</th>\n      <th>type_id</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.loc[df['id'] == np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source, type_id]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>domain</th>\n      <th>type</th>\n      <th>url</th>\n      <th>content</th>\n      <th>scraped_at</th>\n      <th>inserted_at</th>\n      <th>updated_at</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>keywords</th>\n      <th>meta_keywords</th>\n      <th>meta_description</th>\n      <th>tags</th>\n      <th>summary</th>\n      <th>source</th>\n      <th>type_id</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.loc[df['id'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2047      1\n983221    1\n995507    1\n997554    1\n991409    1\n         ..\n717812    1\n707571    1\n705522    1\n711665    1\n0         1\nLength: 999934, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.reset_index(inplace = True, drop = True)\n",
    "df.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "#df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupidx_lst = df.loc[df['content'].duplicated()].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Uniq = df.loc[~df.index.isin(dupidx_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             id              domain        type  \\\n0             2       express.co.uk       rumor   \n1             6  barenakedislam.com        hate   \n2             7  barenakedislam.com        hate   \n3             8  barenakedislam.com        hate   \n4             9  barenakedislam.com        hate   \n...         ...                 ...         ...   \n999895  1170082       wikileaks.org  unreliable   \n999906  1170093       wikileaks.org  unreliable   \n999913  1170100       wikileaks.org  unreliable   \n999923  1170110       wikileaks.org  unreliable   \n999927  1170114       express.co.uk       rumor   \n\n                                                      url  \\\n0       https://www.express.co.uk/news/science/738402/...   \n1       http://barenakedislam.com/category/donald-trum...   \n2       http://barenakedislam.com/category/donald-trum...   \n3       http://barenakedislam.com/2017/12/24/more-winn...   \n4       http://barenakedislam.com/2017/12/25/oh-trump-...   \n...                                                   ...   \n999895  https://www.wikileaks.org/plusd/cables/1974ATO...   \n999906  https://www.wikileaks.org/plusd/cables/1976ABU...   \n999913  https://www.wikileaks.org/plusd/cables/1976ANK...   \n999923  https://www.wikileaks.org/plusd/cables/1976ROM...   \n999927  https://www.express.co.uk/celebrity-news/56649...   \n\n                                                  content  \\\n0       Life is an illusion, at least on a quantum lev...   \n1       Unfortunately, he hasn’t yet attacked her for ...   \n2       The Los Angeles Police Department has been den...   \n3       The White House has decided to quietly withdra...   \n4       “The time has come to cut off the tongues of t...   \n...                                                   ...   \n999895  Raw content\\n\\nPAGE 01 NATO 05116 01 OF 02 201...   \n999906  Raw content\\n\\nCONFIDENTIAL PAGE 01 ABU DH 000...   \n999913  Raw content\\n\\nCONFIDENTIAL PAGE 01 ANKARA 019...   \n999923  Raw content\\n\\nLIMITED OFFICIAL USE PAGE 01 RO...   \n999927  FLYNET Eddie looked unrecognisable as Einar We...   \n\n                        scraped_at                 inserted_at  \\\n0       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n1       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n2       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n3       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n4       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n...                            ...                         ...   \n999895  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n999906  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n999913  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n999923  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n999927  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n\n                        updated_at  \\\n0       2018-02-02 01:19:41.756664   \n1       2018-02-02 01:19:41.756664   \n2       2018-02-02 01:19:41.756664   \n3       2018-02-02 01:19:41.756664   \n4       2018-02-02 01:19:41.756664   \n...                            ...   \n999895  2018-02-02 01:19:41.756664   \n999906  2018-02-02 01:19:41.756664   \n999913  2018-02-02 01:19:41.756664   \n999923  2018-02-02 01:19:41.756664   \n999927  2018-02-02 01:19:41.756664   \n\n                                                    title  \\\n0       Is life an ILLUSION? Researchers prove 'realit...   \n1                                            Donald Trump   \n2                                            Donald Trump   \n3       MORE WINNING! Israeli intelligence source, DEB...   \n4       “Oh, Trump, you coward, you just wait, we will...   \n...                                                   ...   \n999895                                Cable: 1974ATO05116   \n999906                              Cable: 1976ABUDH00021   \n999913                             Cable: 1976ANKARA01989   \n999923                               Cable: 1976ROME16372   \n999927  Eddie Redmayne looks ultra feminine as transge...   \n\n                                                  authors  keywords  \\\n0                                             Sean Martin       NaN   \n1       Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN   \n2       Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN   \n3       Cleavis Nowell, Cleavisnowell, Clarence J. Fei...       NaN   \n4       F.N. Lehner, Don Spilman, Clarence J. Feinour,...       NaN   \n...                                                   ...       ...   \n999895                                                NaN       NaN   \n999906                                                NaN       NaN   \n999913                                                NaN       NaN   \n999923                                                NaN       NaN   \n999927                                        Annie Price       NaN   \n\n       meta_keywords                                   meta_description  \\\n0               ['']  THE UNIVERSE ceases to exist when we are not l...   \n1               ['']                                                NaN   \n2               ['']                                                NaN   \n3               ['']                                                NaN   \n4               ['']                                                NaN   \n...              ...                                                ...   \n999895          ['']                                                NaN   \n999906          ['']                                                NaN   \n999913          ['']                                                NaN   \n999923          ['']                                                NaN   \n999927          ['']  FOR his last role Eddie Redmayne transformed h...   \n\n             tags  summary  source  type_id  \n0             NaN      NaN     NaN        8  \n1             NaN      NaN     NaN        4  \n2             NaN      NaN     NaN        4  \n3             NaN      NaN     NaN        4  \n4             NaN      NaN     NaN        4  \n...           ...      ...     ...      ...  \n999895  View Tags      NaN     NaN       11  \n999906  View Tags      NaN     NaN       11  \n999913  View Tags      NaN     NaN       11  \n999923  View Tags      NaN     NaN       11  \n999927        NaN      NaN     NaN        8  \n\n[660914 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>domain</th>\n      <th>type</th>\n      <th>url</th>\n      <th>content</th>\n      <th>scraped_at</th>\n      <th>inserted_at</th>\n      <th>updated_at</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>keywords</th>\n      <th>meta_keywords</th>\n      <th>meta_description</th>\n      <th>tags</th>\n      <th>summary</th>\n      <th>source</th>\n      <th>type_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>express.co.uk</td>\n      <td>rumor</td>\n      <td>https://www.express.co.uk/news/science/738402/...</td>\n      <td>Life is an illusion, at least on a quantum lev...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Is life an ILLUSION? Researchers prove 'realit...</td>\n      <td>Sean Martin</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>THE UNIVERSE ceases to exist when we are not l...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>6</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/category/donald-trum...</td>\n      <td>Unfortunately, he hasn’t yet attacked her for ...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Donald Trump</td>\n      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/category/donald-trum...</td>\n      <td>The Los Angeles Police Department has been den...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Donald Trump</td>\n      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>8</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/2017/12/24/more-winn...</td>\n      <td>The White House has decided to quietly withdra...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>MORE WINNING! Israeli intelligence source, DEB...</td>\n      <td>Cleavis Nowell, Cleavisnowell, Clarence J. Fei...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>9</td>\n      <td>barenakedislam.com</td>\n      <td>hate</td>\n      <td>http://barenakedislam.com/2017/12/25/oh-trump-...</td>\n      <td>“The time has come to cut off the tongues of t...</td>\n      <td>2018-01-25 16:17:44.789555</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>“Oh, Trump, you coward, you just wait, we will...</td>\n      <td>F.N. Lehner, Don Spilman, Clarence J. Feinour,...</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>999895</td>\n      <td>1170082</td>\n      <td>wikileaks.org</td>\n      <td>unreliable</td>\n      <td>https://www.wikileaks.org/plusd/cables/1974ATO...</td>\n      <td>Raw content\\n\\nPAGE 01 NATO 05116 01 OF 02 201...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Cable: 1974ATO05116</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>View Tags</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <td>999906</td>\n      <td>1170093</td>\n      <td>wikileaks.org</td>\n      <td>unreliable</td>\n      <td>https://www.wikileaks.org/plusd/cables/1976ABU...</td>\n      <td>Raw content\\n\\nCONFIDENTIAL PAGE 01 ABU DH 000...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Cable: 1976ABUDH00021</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>View Tags</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <td>999913</td>\n      <td>1170100</td>\n      <td>wikileaks.org</td>\n      <td>unreliable</td>\n      <td>https://www.wikileaks.org/plusd/cables/1976ANK...</td>\n      <td>Raw content\\n\\nCONFIDENTIAL PAGE 01 ANKARA 019...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Cable: 1976ANKARA01989</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>View Tags</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <td>999923</td>\n      <td>1170110</td>\n      <td>wikileaks.org</td>\n      <td>unreliable</td>\n      <td>https://www.wikileaks.org/plusd/cables/1976ROM...</td>\n      <td>Raw content\\n\\nLIMITED OFFICIAL USE PAGE 01 RO...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Cable: 1976ROME16372</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>NaN</td>\n      <td>View Tags</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <td>999927</td>\n      <td>1170114</td>\n      <td>express.co.uk</td>\n      <td>rumor</td>\n      <td>https://www.express.co.uk/celebrity-news/56649...</td>\n      <td>FLYNET Eddie looked unrecognisable as Einar We...</td>\n      <td>2018-01-25 20:13:50.426130</td>\n      <td>2018-02-02 01:19:41.756632</td>\n      <td>2018-02-02 01:19:41.756664</td>\n      <td>Eddie Redmayne looks ultra feminine as transge...</td>\n      <td>Annie Price</td>\n      <td>NaN</td>\n      <td>['']</td>\n      <td>FOR his last role Eddie Redmayne transformed h...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>660914 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_Uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5222"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_Uniq['type'].loc[df_Uniq['type'] == 'reliable'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "660914"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_Uniq.content.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=> fake (7000, 17) (5600, 17) (1400, 17)\n=> satire (7000, 17) (5600, 17) (1400, 17)\n=> bias (7000, 17) (5600, 17) (1400, 17)\n=> conspiracy (7000, 17) (5600, 17) (1400, 17)\n=> junksci (7000, 17) (5600, 17) (1400, 17)\n=> hate (3112, 17) (2489, 17) (623, 17)\n=> clickbait (7000, 17) (5600, 17) (1400, 17)\n=> unreliable (7000, 17) (5600, 17) (1400, 17)\n=> political (7000, 17) (5600, 17) (1400, 17)\n=> reliable (5222, 17) (4177, 17) (1045, 17)\n\n[Final split]\ntrain, test==> (51466, 17) (12868, 17)\n"
    }
   ],
   "source": [
    "#USE THIS\n",
    "# This can generate a dataset with random purmutation and a max size for each type(can be smaller if desired max is not possible)\n",
    "\n",
    "# max size for type\n",
    "max_size = 7000\n",
    "# traning_set ratio - splits data into traning=ratio,  test and validate=(1-ratio)/2 ex. train=80%, test=10%, validate=10%\n",
    "ratio=0.8\n",
    "# Labels to include - ['fake', 'satire', 'bias', 'conspiracy', 'state', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable'] - all labels\n",
    "use_types = ['fake', 'satire', 'bias', 'conspiracy', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable']\n",
    "# Random seed\n",
    "rnd = 1\n",
    "\n",
    "# initialize dataframes\n",
    "train    = pd.DataFrame(columns = df_Uniq.columns)\n",
    "test     = pd.DataFrame(columns = df_Uniq.columns)\n",
    "\n",
    "# add type to test splits\n",
    "for t in use_types:\n",
    "\n",
    "    # type size\n",
    "    type_size = df_Uniq['type'].loc[df_Uniq['type'] == t].value_counts().min()\n",
    "\n",
    "    # set size of type slice\n",
    "    if type_size < max_size:\n",
    "        tmp = df_Uniq.loc[df_Uniq['type'] == t].sample(n = type_size, random_state=rnd)\n",
    "    else:\n",
    "        tmp = df_Uniq.loc[df_Uniq['type'] == t].sample(n = max_size, random_state=rnd)\n",
    "\n",
    "    # split current type\n",
    "    train_tmp, test_tmp = np.split(tmp, [int(ratio * len(tmp))])\n",
    "\n",
    "    # add tmp to dataframes\n",
    "    train    = pd.concat([train, train_tmp])\n",
    "    test     = pd.concat([test, test_tmp])\n",
    "    \n",
    "    # print split shape\n",
    "    print(\"=>\", t, tmp.shape, train_tmp.shape, test_tmp.shape)\n",
    "\n",
    "print(\"\\n[Final split]\\ntrain, test==>\", train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id_x, domain_x, type_x, url_x, content, scraped_at_x, inserted_at_x, updated_at_x, title_x, authors_x, keywords_x, meta_keywords_x, meta_description_x, tags_x, summary_x, source_x, type_id_x, id_y, domain_y, type_y, url_y, scraped_at_y, inserted_at_y, updated_at_y, title_y, authors_y, keywords_y, meta_keywords_y, meta_description_y, tags_y, summary_y, source_y, type_id_y]\nIndex: []\n\n[0 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_x</th>\n      <th>domain_x</th>\n      <th>type_x</th>\n      <th>url_x</th>\n      <th>content</th>\n      <th>scraped_at_x</th>\n      <th>inserted_at_x</th>\n      <th>updated_at_x</th>\n      <th>title_x</th>\n      <th>authors_x</th>\n      <th>...</th>\n      <th>updated_at_y</th>\n      <th>title_y</th>\n      <th>authors_y</th>\n      <th>keywords_y</th>\n      <th>meta_keywords_y</th>\n      <th>meta_description_y</th>\n      <th>tags_y</th>\n      <th>summary_y</th>\n      <th>source_y</th>\n      <th>type_id_y</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 434
    }
   ],
   "source": [
    "pd.merge(train,test, on =['content'], how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for faster calculation for details, dont run normally\n",
    "# importing and creating df (has to have type_id)\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "#filepath = '/Users/Master/Documents/KU/2.Semester/Datascience/news_sample.csv' #\n",
    "#s = 250                                            # desired sample size\n",
    "#seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "#df = pd.read_csv(filepath, index_col = [0])\n",
    "#content = df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec \n",
    "from gensim.utils import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.set_index('id', inplace = True)\n",
    "from sklearn.utils import shuffle\n",
    "train = shuffle(train, random_state = 1)\n",
    "test = shuffle(test, random_state = 1)\n",
    "train.reset_index(inplace = True, drop = True)\n",
    "test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['this', 'is', 'to', 'token']"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "#this is how the tokenizer works\n",
    "list(tokenize(\"This , is 5to TOKEN\", lowercase = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 1.17 ms, sys: 20 µs, total: 1.19 ms\nWall time: 1.89 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "series_content = train.content\n",
    "#contTok = series_content.apply(nltk.word_tokenize)\n",
    "typeLst = train.type_id.tolist()\n",
    "#np.unique(typeLst, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = test.content\n",
    "test_typeLst = test.type_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_content\n",
    "#test_typeLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try gensim tokenizer\n",
    "testTok = test_content.apply(tokenize,lowercase =True)\n",
    "for i in testTok.index:\n",
    "    testTok[i] = list(testTok[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try gensim tokenizer\n",
    "contTok = series_content.apply(tokenize,lowercase =True)\n",
    "for i in contTok.index:\n",
    "    contTok[i] = list(contTok[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe fallback tokenizer\n",
    "#contTok1 = series_content.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'junksci'"
     },
     "metadata": {},
     "execution_count": 422
    }
   ],
   "source": [
    "train.type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(contTok, [i]) for i, contTok in enumerate(contTok)]\n",
    "#contTok[291496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(contTok))[0]\n",
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Doc2Vec(documents, vector_size = 150, dm = 0, epochs=15, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 22min 15s, sys: 21 s, total: 22min 36s\nWall time: 10min 50s\n"
    }
   ],
   "source": [
    "%%time\n",
    "model1 = Doc2Vec(documents, vector_size = , min_count = 3, window = 10, epochs=10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eventuel træn andre modeller herefter:\n",
    "#%%time\n",
    "#model2 = Doc2Vec(documents, vector_size = 200, dm = 1, min_count = 3, window = 10, epochs= 10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('introverted', 0.3632413148880005),\n ('johansen', 0.32919424772262573),\n ('trick', 0.31969472765922546),\n ('bulge', 0.30862855911254883),\n ('parents', 0.306522011756897),\n ('inr', 0.30332380533218384),\n ('reflective', 0.3025538921356201),\n ('ducing', 0.30231982469558716),\n ('prolifera', 0.30203330516815186),\n ('dialogues', 0.3010951280593872)]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model2.most_similar('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model2.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(47016, 0.7833322882652283),\n (39974, 0.7338676452636719),\n (41431, 0.7269080877304077),\n (2547, 0.7235113382339478),\n (9676, 0.7217190265655518),\n (39357, 0.7115262746810913),\n (45440, 0.7040430307388306),\n (18977, 0.6920127868652344),\n (30585, 0.6893031001091003),\n (5103, 0.6876428127288818)]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model2.docvecs.most_similar(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "39974    fake\nName: type, dtype: object"
     },
     "metadata": {},
     "execution_count": 457
    }
   ],
   "source": [
    "train.type.loc[train.type.index == 39974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.type.loc[train.index == 38424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['clickbait', 'junksci', 'political'], dtype=object), array([3, 4, 3]))"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "#See types of most similar documents for model2\n",
    "#for idx in train.type.loc[train.type == 'fake'].index:\n",
    "sim_labels1 = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels1)):\n",
    "    sim_labels1[i] = train.type.loc[train.type.index == model2.docvecs.most_similar(51398)[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels1,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "16       bias\n21       bias\n23       bias\n34       bias\n43       bias\n         ... \n51398    bias\n51399    bias\n51400    bias\n51416    bias\n51464    bias\nName: type, Length: 5600, dtype: object"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#Lookup indeices for articles with certain types\n",
    "train.type.loc[train.type == 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 traindata\n",
    "train_arrays = np.zeros((model1.docvecs.count,150),dtype=\"float32\")\n",
    "train_labels = np.zeros(model1.docvecs.count,dtype=\"float32\")\n",
    "for i in range(model1.docvecs.count):\n",
    "    train_arrays[i] = model1.docvecs[i]\n",
    "    train_labels[i] = train.type_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 477
    }
   ],
   "source": [
    "model2.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 traindata:\n",
    "train_arrays2 = np.zeros((model2.docvecs.count,150),dtype=\"float32\")\n",
    "train_labels2 = np.zeros(model2.docvecs.count,dtype=\"float32\")\n",
    "for i in range(model2.docvecs.count):\n",
    "    train_arrays2[i] = model2.docvecs[i]\n",
    "    train_labels2[i] = train.type_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(train_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_arrays[0]\n",
    "#train_labels[0]\n",
    "#model1.docvecs.most_similar([train_arrays[0]])\n",
    "#train.loc[train.index == 37400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How infer_vector works:\n",
    "token = \"this is new sentence\".split()\n",
    "new_vector = model1.infer_vector(token)\n",
    "sims = model1.docvecs.most_similar([new_vector])\n",
    "#model2.docvecs.most_similar([new_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_vec = model2.infer_vector(contTok[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.docvecs.most_similar([new_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring vectors for testdata with model1\n",
    "test_arrays = np.zeros((len(test),150),dtype = \"float32\")\n",
    "for i in range(len(test)):\n",
    "    test_arrays[i] = model1.infer_vector(testTok[i],steps = 15)   \n",
    "test_labels = np.array(test_typeLst,dtype=\"float32\")\n",
    "\n",
    "#test_arrays = np.zeros((model1.docvecs.count,150),dtype=\"float32\")\n",
    "#test_labels = np.zeros(model1.docvecs.count,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 6min 29s, sys: 5.3 s, total: 6min 34s\nWall time: 6min 48s\n"
    }
   ],
   "source": [
    "%%time\n",
    "#Inferring vectors for testdata with model2\n",
    "test_arrays2 = np.zeros((len(test),150),dtype = \"float32\")\n",
    "for i in range(len(test)):\n",
    "    test_arrays2[i] = model2.infer_vector(testTok[i], epochs = 20, alpha = 0.025)   \n",
    "test_labels = np.array(test_typeLst,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testTok[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_labels[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(32672, 0.5412675142288208),\n (10444, 0.5094727277755737),\n (23135, 0.49477219581604004),\n (5553, 0.4843190908432007),\n (33264, 0.4779159426689148),\n (32602, 0.4745362102985382),\n (460, 0.4699743688106537),\n (24024, 0.468875527381897),\n (11487, 0.4654442071914673),\n (2246, 0.46349072456359863)]"
     },
     "metadata": {},
     "execution_count": 568
    }
   ],
   "source": [
    "model1.docvecs.most_similar([test_arrays[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3642    clickbait\nName: type, dtype: object"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "test.type.loc[test.type.index == 3642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7e4e95c284f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msim_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msim_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "#Find originalarticle types most similar to inferred vector by model1:\n",
    "sim_labels = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels)):\n",
    "    sim_labels[i] = train.type.loc[train.type.index == model1.docvecs.most_similar([test_arrays[10]])[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(15221, 0.460197776556015),\n (20051, 0.4442721903324127),\n (37955, 0.4413350224494934),\n (6278, 0.4317403733730316),\n (17709, 0.4302103519439697),\n (29647, 0.42933136224746704),\n (19457, 0.4270772933959961),\n (122, 0.42285194993019104),\n (32331, 0.42190662026405334),\n (21916, 0.421882688999176)]"
     },
     "metadata": {},
     "execution_count": 350
    }
   ],
   "source": [
    "model2.docvecs.most_similar([test_arrays2[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'satire'"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "train.type[10004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(14004, 0.6460142731666565),\n (31820, 0.6411257982254028),\n (36654, 0.6238328218460083),\n (10004, 0.6183276176452637),\n (4258, 0.612575113773346),\n (9671, 0.6100050210952759),\n (45557, 0.6094460487365723),\n (36745, 0.6056312322616577),\n (46957, 0.6026122570037842),\n (12744, 0.6022600531578064)]"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "model2.docvecs.most_similar([test_arrays2[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['clickbait', 'political', 'reliable'], dtype=object), array([1, 2, 7]))"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "#Find originalarticle types most similar to inferred vector by model2:\n",
    "sim_labels = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels)):\n",
    "    sim_labels[i] = train.type.loc[train.type.index == model2.docvecs.most_similar([test_arrays2[75]])[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([   11,    17,    25,    29,    54,    63,    75,    88,    90,\n              124,\n            ...\n            12742, 12748, 12762, 12784, 12803, 12816, 12818, 12826, 12851,\n            12866],\n           dtype='int64', length=1045)"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "#Get indices for testarticles of a certain type:\n",
    "test.type.loc[test.type == 'reliable'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.docvecs.most_similar([test_arrays[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.type.loc[train.type == 'bias'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_arrays2)\n",
    "X_train = scaler.transform(train_arrays2)\n",
    "X_test = scaler.transform(test_arrays2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2489"
     },
     "metadata": {},
     "execution_count": 411
    }
   ],
   "source": [
    "len(train.loc[train.type == 'hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.6070711128967456"
     },
     "metadata": {},
     "execution_count": 405
    }
   ],
   "source": [
    "4000/2489\n",
    "2489/400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=None, penalty='l2',\n                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n                   warm_start=True)"
     },
     "metadata": {},
     "execution_count": 527
    }
   ],
   "source": [
    "#Now train a logistic classifier:\n",
    "#can try gridsearch for parameters:\n",
    "#Logistic = LogisticRegression()\n",
    "#grid = {\"C\" :np.logspace(0,4,10), \"penalty\": [\"l1\", \"l2\"]}\n",
    "#logClf = GridSearchCV(Logistic, grid, cv = 5)\n",
    "#best_model = logClf.fit(X_train, train_labels)\n",
    "clfLog = LogisticRegression(C = 0.01,multi_class = 'multinomial', solver = 'saga', penalty = 'l2', warm_start = True)\n",
    "clfLog.fit(X_train, train_labels2)\n",
    "\n",
    "#classifier.fit(X_train,train_labels)\n",
    "#classifier.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6565899906745415"
     },
     "metadata": {},
     "execution_count": 528
    }
   ],
   "source": [
    "clfLog.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_labels\n",
    "#y_true\n",
    "y_pred = clfLog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[433,  59,  96,  13, 160,  49, 109,  45,  30,   6],\n       [ 50, 546,  49,  12,  51,  42, 119,  51,  72,   8],\n       [ 75,  60, 530,  14,  82,  63, 105,  22,  43,   6],\n       [ 15,  18,  33, 852,  15,  33,  17,   5,  11,   1],\n       [ 39,  38,  28,   8, 415,  11,  44,  21,  14,   5],\n       [ 22,  41,  41,   7,  11, 807,  15,  21,  35,   0],\n       [ 93, 137,  76,  14,  76,  22, 468,  58,  50,   6],\n       [ 63,  64,  16,   5,  51,  25,  46, 692,  37,   1],\n       [ 39,  79,  49,   8,  34,  31,  56,  18, 682,   4],\n       [ 18,  40,  18,   4,  11,  11,  27,   9,   8, 854]])"
     },
     "metadata": {},
     "execution_count": 415
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6406526031383144"
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "source": [
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 530
    }
   ],
   "source": [
    "#Try GaussianNB:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clfNB = GaussianNB()\n",
    "clfNB.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5231582219459123"
     },
     "metadata": {},
     "execution_count": 531
    }
   ],
   "source": [
    "clfNB.score(X_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0)"
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LinSvm = LinearSVC()\n",
    "LinSvm.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6350410474903876"
     },
     "metadata": {},
     "execution_count": 253
    }
   ],
   "source": [
    "LinSvm.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 532
    }
   ],
   "source": [
    "#rbf kernel = 0 .72, poly kernel = 0.7\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#parameters = {'C':[1,10], 'kernel': ('linear','rbf')}\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,train_labels2)\n",
    "#clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7192259869443581"
     },
     "metadata": {},
     "execution_count": 533
    }
   ],
   "source": [
    "clf.score(X_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[603,  51,  73,  23,  50,  27, 106,  33,  34,   0],\n       [101, 614,  37,  15,  13,  24,  97,  38,  61,   0],\n       [117,  50, 578,  40,  34,  42,  98,   5,  34,   2],\n       [ 17,  10,  25, 890,   5,  22,  19,   5,   7,   0],\n       [ 81,  24,  31,  15, 382,   8,  54,  16,  11,   1],\n       [ 31,  34,  45,  17,   5, 824,  12,   7,  24,   1],\n       [173,  92,  72,  28,  27,  18, 501,  31,  57,   1],\n       [ 42,  37,  13,   4,   8,   7,  33, 829,  27,   0],\n       [ 58,  46,  25,  25,  11,  24,  41,  12, 755,   3],\n       [ 21,  47,   8,   3,   6,   8,  21,   7,   9, 870]])"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred_svm)\n",
    "#np.unique(train_labels2 == typeLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')"
     },
     "metadata": {},
     "execution_count": 534
    }
   ],
   "source": [
    "#Decicion tree\n",
    "from sklearn import tree\n",
    "\n",
    "treeClf = tree.DecisionTreeClassifier()\n",
    "treeClf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.2661641280696301"
     },
     "metadata": {},
     "execution_count": 543
    }
   ],
   "source": [
    "treeClf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of labels=38489 does not match number of samples=51466",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-a8d6210465ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mforestClf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mforestClf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 250\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=38489 does not match number of samples=51466"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forestClf = RandomForestClassifier()\n",
    "forestClf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.35708734846129936"
     },
     "metadata": {},
     "execution_count": 542
    }
   ],
   "source": [
    "forestClf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_clf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5564792684194119"
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "KNN_clf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  9., 11.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 605
    }
   ],
   "source": [
    "np.unique(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[252, 131, 121,  46, 244,  63, 101,  28,  12,   2],\n       [ 27, 504,  69,  19,  99,  87, 103,  67,  23,   2],\n       [ 54, 102, 408,  54, 186,  81,  79,  15,  21,   0],\n       [ 30,  89, 150, 266, 181, 124,  92,  19,  44,   5],\n       [ 11,  50,  63,  13, 422,  21,  25,  13,   5,   0],\n       [  8,  55,  68,  20, 130, 691,  18,   8,   2,   0],\n       [ 40, 186,  94,  38, 182,  46, 363,  32,  18,   1],\n       [ 25,  79,  13,  10, 178,  54,  35, 591,  15,   0],\n       [ 16, 119,  50,  67,  83,  63,  78,  43, 474,   7],\n       [ 11,  46,  14,   9, 167,  15,  22,   6,   3, 707]])"
     },
     "metadata": {},
     "execution_count": 593
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try tf-idf svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(train[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scikit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "clf_NB = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('NB', MultinomialNB()),])\n",
    "                   \n",
    "# Support vector machine\n",
    "clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('svm', SGDClassifier()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.fit(series_content,typeLst )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([ True]), array([9623]))"
     },
     "metadata": {},
     "execution_count": 631
    }
   ],
   "source": [
    "np.unique(test_labels == test_typeLst, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7225397485191728"
     },
     "metadata": {},
     "execution_count": 646
    }
   ],
   "source": [
    "clf_svm.score(test_content, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-645-bc1c4179375a>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-645-bc1c4179375a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    clf_svm.score(test_content, test_labels)clf_svm.score(test_content, test_labels)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "clf_svm.score(test_content, test_labels)clf_svm.score(test_content, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 585
    }
   ],
   "source": [
    "#X_train\n",
    "#len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 589
    }
   ],
   "source": [
    "train_labels2 = np.array(train_labels2)\n",
    "len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train)\n",
    "#len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# laver modellen\n",
    "model = tf.keras.models.Sequential()\n",
    "# tilføjer et input på modellen\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# relu er default aktiverings funktion. Lav den om hvis resultatet ikke er godt nok\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "# jeg tilføjer 2 lag til netwærket. Dette er fordi det er en simpel opgave\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "\n",
    "#antallet (10) er antal output. Det er 10 tal i datasettet derfor skal der være et 10 tal\n",
    "model.add(tf.keras.layers.Dense(12, activation=tf.nn.softmax))\n",
    "\n",
    "# Dette er den mest komplexe del. adam er goto. Hvis der kun er 2 løsninger så brug binary_categorical_crossentropy eller binary_crossentropy i stedet for sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/3\n1609/1609 [==============================] - 5s 3ms/step - loss: 1.8646 - accuracy: 0.3420\nEpoch 2/3\n1609/1609 [==============================] - 4s 3ms/step - loss: 1.3896 - accuracy: 0.5305\nEpoch 3/3\n1609/1609 [==============================] - 5s 3ms/step - loss: 1.2958 - accuracy: 0.5623\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x268e09950>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "model.fit(train_arrays2, train_labels2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-81379e84d0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmySentTok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmySentTok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "mySent = \"These are my sentences in the books\"\n",
    "mySentTok = word_tokenize(mySent)\n",
    "ps = PorterStemmer()\n",
    "for w in mySentTok:\n",
    "    mySentTok[w] = ps.stem(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.16-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}