{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>rumor</td>\n",
       "      <td>https://www.express.co.uk/news/science/738402/...</td>\n",
       "      <td>Life is an illusion, at least on a quantum lev...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Is life an ILLUSION? Researchers prove 'realit...</td>\n",
       "      <td>Sean Martin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>THE UNIVERSE ceases to exist when we are not l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>Unfortunately, he hasn’t yet attacked her for ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>The Los Angeles Police Department has been den...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/24/more-winn...</td>\n",
       "      <td>The White House has decided to quietly withdra...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>MORE WINNING! Israeli intelligence source, DEB...</td>\n",
       "      <td>Cleavis Nowell, Cleavisnowell, Clarence J. Fei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/25/oh-trump-...</td>\n",
       "      <td>“The time has come to cut off the tongues of t...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>“Oh, Trump, you coward, you just wait, we will...</td>\n",
       "      <td>F.N. Lehner, Don Spilman, Clarence J. Feinour,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id              domain   type  \\\n",
       "0  2       express.co.uk  rumor   \n",
       "1  6  barenakedislam.com   hate   \n",
       "2  7  barenakedislam.com   hate   \n",
       "3  8  barenakedislam.com   hate   \n",
       "4  9  barenakedislam.com   hate   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.express.co.uk/news/science/738402/...   \n",
       "1  http://barenakedislam.com/category/donald-trum...   \n",
       "2  http://barenakedislam.com/category/donald-trum...   \n",
       "3  http://barenakedislam.com/2017/12/24/more-winn...   \n",
       "4  http://barenakedislam.com/2017/12/25/oh-trump-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Life is an illusion, at least on a quantum lev...   \n",
       "1  Unfortunately, he hasn’t yet attacked her for ...   \n",
       "2  The Los Angeles Police Department has been den...   \n",
       "3  The White House has decided to quietly withdra...   \n",
       "4  “The time has come to cut off the tongues of t...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-02 01:19:41.756664   \n",
       "1  2018-02-02 01:19:41.756664   \n",
       "2  2018-02-02 01:19:41.756664   \n",
       "3  2018-02-02 01:19:41.756664   \n",
       "4  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                               title  \\\n",
       "0  Is life an ILLUSION? Researchers prove 'realit...   \n",
       "1                                       Donald Trump   \n",
       "2                                       Donald Trump   \n",
       "3  MORE WINNING! Israeli intelligence source, DEB...   \n",
       "4  “Oh, Trump, you coward, you just wait, we will...   \n",
       "\n",
       "                                             authors  keywords meta_keywords  \\\n",
       "0                                        Sean Martin       NaN          ['']   \n",
       "1  Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN          ['']   \n",
       "2  Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN          ['']   \n",
       "3  Cleavis Nowell, Cleavisnowell, Clarence J. Fei...       NaN          ['']   \n",
       "4  F.N. Lehner, Don Spilman, Clarence J. Feinour,...       NaN          ['']   \n",
       "\n",
       "                                    meta_description tags  summary  source  \\\n",
       "0  THE UNIVERSE ceases to exist when we are not l...  NaN      NaN     NaN   \n",
       "1                                                NaN  NaN      NaN     NaN   \n",
       "2                                                NaN  NaN      NaN     NaN   \n",
       "3                                                NaN  NaN      NaN     NaN   \n",
       "4                                                NaN  NaN      NaN     NaN   \n",
       "\n",
       "   type_id  \n",
       "0        8  \n",
       "1        4  \n",
       "2        4  \n",
       "3        4  \n",
       "4        4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and creating df (has to have type_id)\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random)\n",
    "#filepath = '../Data_sample/FakeNewsCorpus_250.csv' # 250 rows of FakeNewsCorpus\n",
    "filepath = '/Users/Master/Documents/KU/2.Semester/Datascience/1mioraw.csv'       # 1 mil rows raw\n",
    "#s = 1000000                                            # desired sample size\n",
    "#seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_csv(filepath, index_col = [0])\n",
    "df[\"content\"] = df[\"content\"].astype(str)\n",
    "# create type_id\n",
    "df['type_id'] = df.groupby(['type']).ngroup()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933],\n",
       "      dtype='object', length=1000000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 5
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df['id'] = pd.to_numeric(df['id'], errors = 'coerce', downcast = 'integer')\n",
    "df.dropna(subset=['id'], inplace = True)\n",
    "#df.drop_duplicates(subset = 'content', inplace = True)\n",
    "df.drop_duplicates(subset = 'id', inplace = True)\n",
    "df.id = df.id.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source, type_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 4
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "df.loc[df['id'] == np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source, type_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 5
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "df.loc[df['id'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047      1\n",
       "983221    1\n",
       "995507    1\n",
       "997554    1\n",
       "991409    1\n",
       "         ..\n",
       "717812    1\n",
       "707571    1\n",
       "705522    1\n",
       "711665    1\n",
       "0         1\n",
       "Length: 999934, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 6
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "df.reset_index(inplace = True, drop = True)\n",
    "df.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "#df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupidx_lst = df.loc[df['content'].duplicated()].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Uniq = df.loc[~df.index.isin(dupidx_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>rumor</td>\n",
       "      <td>https://www.express.co.uk/news/science/738402/...</td>\n",
       "      <td>Life is an illusion, at least on a quantum lev...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Is life an ILLUSION? Researchers prove 'realit...</td>\n",
       "      <td>Sean Martin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>THE UNIVERSE ceases to exist when we are not l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>Unfortunately, he hasn’t yet attacked her for ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>The Los Angeles Police Department has been den...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/24/more-winn...</td>\n",
       "      <td>The White House has decided to quietly withdra...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>MORE WINNING! Israeli intelligence source, DEB...</td>\n",
       "      <td>Cleavis Nowell, Cleavisnowell, Clarence J. Fei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/25/oh-trump-...</td>\n",
       "      <td>“The time has come to cut off the tongues of t...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>“Oh, Trump, you coward, you just wait, we will...</td>\n",
       "      <td>F.N. Lehner, Don Spilman, Clarence J. Feinour,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999895</td>\n",
       "      <td>1170082</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>https://www.wikileaks.org/plusd/cables/1974ATO...</td>\n",
       "      <td>Raw content\\n\\nPAGE 01 NATO 05116 01 OF 02 201...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Cable: 1974ATO05116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999906</td>\n",
       "      <td>1170093</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>https://www.wikileaks.org/plusd/cables/1976ABU...</td>\n",
       "      <td>Raw content\\n\\nCONFIDENTIAL PAGE 01 ABU DH 000...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Cable: 1976ABUDH00021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999913</td>\n",
       "      <td>1170100</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>https://www.wikileaks.org/plusd/cables/1976ANK...</td>\n",
       "      <td>Raw content\\n\\nCONFIDENTIAL PAGE 01 ANKARA 019...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Cable: 1976ANKARA01989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999923</td>\n",
       "      <td>1170110</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>https://www.wikileaks.org/plusd/cables/1976ROM...</td>\n",
       "      <td>Raw content\\n\\nLIMITED OFFICIAL USE PAGE 01 RO...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Cable: 1976ROME16372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999927</td>\n",
       "      <td>1170114</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>rumor</td>\n",
       "      <td>https://www.express.co.uk/celebrity-news/56649...</td>\n",
       "      <td>FLYNET Eddie looked unrecognisable as Einar We...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Eddie Redmayne looks ultra feminine as transge...</td>\n",
       "      <td>Annie Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>FOR his last role Eddie Redmayne transformed h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660914 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id              domain        type  \\\n",
       "0             2       express.co.uk       rumor   \n",
       "1             6  barenakedislam.com        hate   \n",
       "2             7  barenakedislam.com        hate   \n",
       "3             8  barenakedislam.com        hate   \n",
       "4             9  barenakedislam.com        hate   \n",
       "...         ...                 ...         ...   \n",
       "999895  1170082       wikileaks.org  unreliable   \n",
       "999906  1170093       wikileaks.org  unreliable   \n",
       "999913  1170100       wikileaks.org  unreliable   \n",
       "999923  1170110       wikileaks.org  unreliable   \n",
       "999927  1170114       express.co.uk       rumor   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.express.co.uk/news/science/738402/...   \n",
       "1       http://barenakedislam.com/category/donald-trum...   \n",
       "2       http://barenakedislam.com/category/donald-trum...   \n",
       "3       http://barenakedislam.com/2017/12/24/more-winn...   \n",
       "4       http://barenakedislam.com/2017/12/25/oh-trump-...   \n",
       "...                                                   ...   \n",
       "999895  https://www.wikileaks.org/plusd/cables/1974ATO...   \n",
       "999906  https://www.wikileaks.org/plusd/cables/1976ABU...   \n",
       "999913  https://www.wikileaks.org/plusd/cables/1976ANK...   \n",
       "999923  https://www.wikileaks.org/plusd/cables/1976ROM...   \n",
       "999927  https://www.express.co.uk/celebrity-news/56649...   \n",
       "\n",
       "                                                  content  \\\n",
       "0       Life is an illusion, at least on a quantum lev...   \n",
       "1       Unfortunately, he hasn’t yet attacked her for ...   \n",
       "2       The Los Angeles Police Department has been den...   \n",
       "3       The White House has decided to quietly withdra...   \n",
       "4       “The time has come to cut off the tongues of t...   \n",
       "...                                                   ...   \n",
       "999895  Raw content\\n\\nPAGE 01 NATO 05116 01 OF 02 201...   \n",
       "999906  Raw content\\n\\nCONFIDENTIAL PAGE 01 ABU DH 000...   \n",
       "999913  Raw content\\n\\nCONFIDENTIAL PAGE 01 ANKARA 019...   \n",
       "999923  Raw content\\n\\nLIMITED OFFICIAL USE PAGE 01 RO...   \n",
       "999927  FLYNET Eddie looked unrecognisable as Einar We...   \n",
       "\n",
       "                        scraped_at                 inserted_at  \\\n",
       "0       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "1       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "2       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "3       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "4       2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "...                            ...                         ...   \n",
       "999895  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "999906  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "999913  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "999923  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "999927  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                        updated_at  \\\n",
       "0       2018-02-02 01:19:41.756664   \n",
       "1       2018-02-02 01:19:41.756664   \n",
       "2       2018-02-02 01:19:41.756664   \n",
       "3       2018-02-02 01:19:41.756664   \n",
       "4       2018-02-02 01:19:41.756664   \n",
       "...                            ...   \n",
       "999895  2018-02-02 01:19:41.756664   \n",
       "999906  2018-02-02 01:19:41.756664   \n",
       "999913  2018-02-02 01:19:41.756664   \n",
       "999923  2018-02-02 01:19:41.756664   \n",
       "999927  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                    title  \\\n",
       "0       Is life an ILLUSION? Researchers prove 'realit...   \n",
       "1                                            Donald Trump   \n",
       "2                                            Donald Trump   \n",
       "3       MORE WINNING! Israeli intelligence source, DEB...   \n",
       "4       “Oh, Trump, you coward, you just wait, we will...   \n",
       "...                                                   ...   \n",
       "999895                                Cable: 1974ATO05116   \n",
       "999906                              Cable: 1976ABUDH00021   \n",
       "999913                             Cable: 1976ANKARA01989   \n",
       "999923                               Cable: 1976ROME16372   \n",
       "999927  Eddie Redmayne looks ultra feminine as transge...   \n",
       "\n",
       "                                                  authors  keywords  \\\n",
       "0                                             Sean Martin       NaN   \n",
       "1       Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN   \n",
       "2       Linda Rivera, Conrad Calvano, Az Gal, Lincoln ...       NaN   \n",
       "3       Cleavis Nowell, Cleavisnowell, Clarence J. Fei...       NaN   \n",
       "4       F.N. Lehner, Don Spilman, Clarence J. Feinour,...       NaN   \n",
       "...                                                   ...       ...   \n",
       "999895                                                NaN       NaN   \n",
       "999906                                                NaN       NaN   \n",
       "999913                                                NaN       NaN   \n",
       "999923                                                NaN       NaN   \n",
       "999927                                        Annie Price       NaN   \n",
       "\n",
       "       meta_keywords                                   meta_description  \\\n",
       "0               ['']  THE UNIVERSE ceases to exist when we are not l...   \n",
       "1               ['']                                                NaN   \n",
       "2               ['']                                                NaN   \n",
       "3               ['']                                                NaN   \n",
       "4               ['']                                                NaN   \n",
       "...              ...                                                ...   \n",
       "999895          ['']                                                NaN   \n",
       "999906          ['']                                                NaN   \n",
       "999913          ['']                                                NaN   \n",
       "999923          ['']                                                NaN   \n",
       "999927          ['']  FOR his last role Eddie Redmayne transformed h...   \n",
       "\n",
       "             tags  summary  source  type_id  \n",
       "0             NaN      NaN     NaN        8  \n",
       "1             NaN      NaN     NaN        4  \n",
       "2             NaN      NaN     NaN        4  \n",
       "3             NaN      NaN     NaN        4  \n",
       "4             NaN      NaN     NaN        4  \n",
       "...           ...      ...     ...      ...  \n",
       "999895  View Tags      NaN     NaN       11  \n",
       "999906  View Tags      NaN     NaN       11  \n",
       "999913  View Tags      NaN     NaN       11  \n",
       "999923  View Tags      NaN     NaN       11  \n",
       "999927        NaN      NaN     NaN        8  \n",
       "\n",
       "[660914 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Uniq['type'].loc[df_Uniq['type'] == 'reliable'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Uniq.content.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
<<<<<<< HEAD
     "text": "=> fake (7000, 17) (5600, 17) (1400, 17)\n=> satire (7000, 17) (5600, 17) (1400, 17)\n=> bias (7000, 17) (5600, 17) (1400, 17)\n=> conspiracy (7000, 17) (5600, 17) (1400, 17)\n=> junksci (7000, 17) (5600, 17) (1400, 17)\n=> hate (3112, 17) (2489, 17) (623, 17)\n=> clickbait (7000, 17) (5600, 17) (1400, 17)\n=> unreliable (7000, 17) (5600, 17) (1400, 17)\n=> political (7000, 17) (5600, 17) (1400, 17)\n=> reliable (5222, 17) (4177, 17) (1045, 17)\n\n[Final split]\ntrain, test==> (51466, 17) (12868, 17)\n"
=======
     "output_type": "stream",
     "text": [
      "=> fake (5000, 17) (4000, 17) (1000, 17)\n",
      "=> satire (5000, 17) (4000, 17) (1000, 17)\n",
      "=> bias (5000, 17) (4000, 17) (1000, 17)\n",
      "=> conspiracy (5000, 17) (4000, 17) (1000, 17)\n",
      "=> junksci (5000, 17) (4000, 17) (1000, 17)\n",
      "=> hate (3112, 17) (2489, 17) (623, 17)\n",
      "=> clickbait (5000, 17) (4000, 17) (1000, 17)\n",
      "=> unreliable (5000, 17) (4000, 17) (1000, 17)\n",
      "=> political (5000, 17) (4000, 17) (1000, 17)\n",
      "=> reliable (5000, 17) (4000, 17) (1000, 17)\n",
      "\n",
      "[Final split]\n",
      "train, test, validate ==> (38489, 17) (9623, 17)\n"
     ]
>>>>>>> master
    }
   ],
   "source": [
    "#USE THIS\n",
    "# This can generate a dataset with random purmutation and a max size for each type(can be smaller if desired max is not possible)\n",
    "\n",
    "# max size for type\n",
    "max_size = 7000\n",
    "# traning_set ratio - splits data into traning=ratio,  test and validate=(1-ratio)/2 ex. train=80%, test=10%, validate=10%\n",
    "ratio=0.8\n",
    "# Labels to include - ['fake', 'satire', 'bias', 'conspiracy', 'state', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable'] - all labels\n",
    "use_types = ['fake', 'satire', 'bias', 'conspiracy', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable']\n",
    "# Random seed\n",
    "rnd = 1\n",
    "\n",
    "# initialize dataframes\n",
    "train    = pd.DataFrame(columns = df_Uniq.columns)\n",
    "test     = pd.DataFrame(columns = df_Uniq.columns)\n",
    "\n",
    "# add type to test splits\n",
    "for t in use_types:\n",
    "\n",
    "    # type size\n",
    "    type_size = df_Uniq['type'].loc[df_Uniq['type'] == t].value_counts().min()\n",
    "\n",
    "    # set size of type slice\n",
    "    if type_size < max_size:\n",
    "        tmp = df_Uniq.loc[df_Uniq['type'] == t].sample(n = type_size, random_state=rnd)\n",
    "    else:\n",
    "        tmp = df_Uniq.loc[df_Uniq['type'] == t].sample(n = max_size, random_state=rnd)\n",
    "\n",
    "    # split current type\n",
    "    train_tmp, test_tmp = np.split(tmp, [int(ratio * len(tmp))])\n",
    "\n",
    "    # add tmp to dataframes\n",
    "    train    = pd.concat([train, train_tmp])\n",
    "    test     = pd.concat([test, test_tmp])\n",
    "    \n",
    "    # print split shape\n",
    "    print(\"=>\", t, tmp.shape, train_tmp.shape, test_tmp.shape)\n",
    "\n",
    "print(\"\\n[Final split]\\ntrain, test==>\", train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>domain_x</th>\n",
       "      <th>type_x</th>\n",
       "      <th>url_x</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at_x</th>\n",
       "      <th>inserted_at_x</th>\n",
       "      <th>updated_at_x</th>\n",
       "      <th>title_x</th>\n",
       "      <th>authors_x</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_at_y</th>\n",
       "      <th>title_y</th>\n",
       "      <th>authors_y</th>\n",
       "      <th>keywords_y</th>\n",
       "      <th>meta_keywords_y</th>\n",
       "      <th>meta_description_y</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>summary_y</th>\n",
       "      <th>source_y</th>\n",
       "      <th>type_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_x, domain_x, type_x, url_x, content, scraped_at_x, inserted_at_x, updated_at_x, title_x, authors_x, keywords_x, meta_keywords_x, meta_description_x, tags_x, summary_x, source_x, type_id_x, id_y, domain_y, type_y, url_y, scraped_at_y, inserted_at_y, updated_at_y, title_y, authors_y, keywords_y, meta_keywords_y, meta_description_y, tags_y, summary_y, source_y, type_id_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 434
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "pd.merge(train,test, on =['content'], how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for faster calculation for details, dont run normally\n",
    "# importing and creating df (has to have type_id)\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "#filepath = '/Users/Master/Documents/KU/2.Semester/Datascience/news_sample.csv' #\n",
    "#s = 250                                            # desired sample size\n",
    "#seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "#df = pd.read_csv(filepath, index_col = [0])\n",
    "#content = df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bag', 'is', 'up']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> master
   "source": [
    "import gensim \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec \n",
    "from gensim.utils import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38303</td>\n",
       "      <td>862410</td>\n",
       "      <td>christianpost.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://www.christianpost.com/news/evangelical...</td>\n",
       "      <td>The views expressed by the author do not neces...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Evangelical Pastors Advise Trump: Why Are Chri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>I'm extremely saddened by the negative comment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8967</td>\n",
       "      <td>946094</td>\n",
       "      <td>russia-insider.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>http://russia-insider.com/en/ukraine/2015/02/1...</td>\n",
       "      <td>US diplomats have been openly talking about ho...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Will IMF Try to Stiff Russia for Ukraine Billi...</td>\n",
       "      <td>Michael Hudson, Gilbert Doctorow, Charles Baus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['russia news']</td>\n",
       "      <td>This is an excerpt from an article that origin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5033</td>\n",
       "      <td>588118</td>\n",
       "      <td>us.blastingnews.com</td>\n",
       "      <td>satire</td>\n",
       "      <td>http://us.blastingnews.com/showbiz-tv/2016/10/...</td>\n",
       "      <td>After the grand success of Priyadarshan's \"Opp...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>'Pulimurugan' Malayalam movie review: live pub...</td>\n",
       "      <td>Blasting News, Kendall Thomas, Hailey Jones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>The Mohanlal, Kamalini Mukherjee and Jagapati ...</td>\n",
       "      <td>4218 followers Dragon Ball Super, Movies, 4062...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38193</td>\n",
       "      <td>473608</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://nutritionfacts.org/video/treating-pros...</td>\n",
       "      <td>Below is an approximation of this video’s audi...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Treating Prostate Cancer with Green Tea</td>\n",
       "      <td>Michael Greger M.D. Faclm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Green tea is put to the test against precancer...</td>\n",
       "      <td>liver health, black tea, men's health, Volume ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29134</td>\n",
       "      <td>1011888</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>https://www.wikileaks.org/plusd/cables/1973VIE...</td>\n",
       "      <td>Raw content\\n\\nSECRET PAGE 01 VIENNA 08803 242...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Cable: 1973VIENNA08803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Tags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18585</td>\n",
       "      <td>192675</td>\n",
       "      <td>wakingtimes.com</td>\n",
       "      <td>junksci</td>\n",
       "      <td>http://www.wakingtimes.com/2012/07/11/can-we-e...</td>\n",
       "      <td>Flickr – Apple – ✿ nicolas_gent ✿ was last mod...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>✿ nicolas_gent ✿</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23357</td>\n",
       "      <td>1001832</td>\n",
       "      <td>politicususa.com</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>http://www.politicususa.com/2008/08/15/specula...</td>\n",
       "      <td>Both Jeff Greenfield of CBS News and Marc Ambi...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Speculation Grows that Obama Will Announce His...</td>\n",
       "      <td>Jason Easley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book review, news, Obama, NBC, ABC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26069</td>\n",
       "      <td>625831</td>\n",
       "      <td>politicususa.com</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>http://www.politicususa.com/tag/melania-trump-...</td>\n",
       "      <td>\"In the second passage...22 words out of 26 wo...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Melania Trump Speech at Republican Convention ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18006</td>\n",
       "      <td>468329</td>\n",
       "      <td>healthnutnews.com</td>\n",
       "      <td>junksci</td>\n",
       "      <td>https://www.healthnutnews.com/what-to-do-if-cp...</td>\n",
       "      <td>We live in a society that sadly, necessitates ...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>What to do if CPS shows up at your door</td>\n",
       "      <td>Erin Elizabeth, Wendy Perry Harding, Sara Szok...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['medical kidnap', 'health', 'rights', 'cps', ...</td>\n",
       "      <td>We live in a society that sadly, necessitates ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24685</td>\n",
       "      <td>122242</td>\n",
       "      <td>liberalamerica.org</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>https://www.liberalamerica.org/2016/08/19/teen...</td>\n",
       "      <td>Going to the movies can be expensive; $8.00 fo...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Teen Girls Pretend To Be Pregnant To Smuggle W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Going to the movies is expensive. A group of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38489 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id               domain        type  \\\n",
       "38303   862410    christianpost.com    reliable   \n",
       "8967    946094   russia-insider.com        bias   \n",
       "5033    588118  us.blastingnews.com      satire   \n",
       "38193   473608   nutritionfacts.org    reliable   \n",
       "29134  1011888        wikileaks.org  unreliable   \n",
       "...        ...                  ...         ...   \n",
       "18585   192675      wakingtimes.com     junksci   \n",
       "23357  1001832     politicususa.com   clickbait   \n",
       "26069   625831     politicususa.com   clickbait   \n",
       "18006   468329    healthnutnews.com     junksci   \n",
       "24685   122242   liberalamerica.org   clickbait   \n",
       "\n",
       "                                                     url  \\\n",
       "38303  https://www.christianpost.com/news/evangelical...   \n",
       "8967   http://russia-insider.com/en/ukraine/2015/02/1...   \n",
       "5033   http://us.blastingnews.com/showbiz-tv/2016/10/...   \n",
       "38193  https://nutritionfacts.org/video/treating-pros...   \n",
       "29134  https://www.wikileaks.org/plusd/cables/1973VIE...   \n",
       "...                                                  ...   \n",
       "18585  http://www.wakingtimes.com/2012/07/11/can-we-e...   \n",
       "23357  http://www.politicususa.com/2008/08/15/specula...   \n",
       "26069  http://www.politicususa.com/tag/melania-trump-...   \n",
       "18006  https://www.healthnutnews.com/what-to-do-if-cp...   \n",
       "24685  https://www.liberalamerica.org/2016/08/19/teen...   \n",
       "\n",
       "                                                 content  \\\n",
       "38303  The views expressed by the author do not neces...   \n",
       "8967   US diplomats have been openly talking about ho...   \n",
       "5033   After the grand success of Priyadarshan's \"Opp...   \n",
       "38193  Below is an approximation of this video’s audi...   \n",
       "29134  Raw content\\n\\nSECRET PAGE 01 VIENNA 08803 242...   \n",
       "...                                                  ...   \n",
       "18585  Flickr – Apple – ✿ nicolas_gent ✿ was last mod...   \n",
       "23357  Both Jeff Greenfield of CBS News and Marc Ambi...   \n",
       "26069  \"In the second passage...22 words out of 26 wo...   \n",
       "18006  We live in a society that sadly, necessitates ...   \n",
       "24685  Going to the movies can be expensive; $8.00 fo...   \n",
       "\n",
       "                       scraped_at                 inserted_at  \\\n",
       "38303  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "8967   2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "5033   2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "38193  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "29134  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "...                           ...                         ...   \n",
       "18585  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "23357  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "26069  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "18006  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "24685  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                       updated_at  \\\n",
       "38303  2018-02-02 01:19:41.756664   \n",
       "8967   2018-02-02 01:19:41.756664   \n",
       "5033   2018-02-02 01:19:41.756664   \n",
       "38193  2018-02-02 01:19:41.756664   \n",
       "29134  2018-02-02 01:19:41.756664   \n",
       "...                           ...   \n",
       "18585  2018-02-02 01:19:41.756664   \n",
       "23357  2018-02-02 01:19:41.756664   \n",
       "26069  2018-02-02 01:19:41.756664   \n",
       "18006  2018-02-02 01:19:41.756664   \n",
       "24685  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                   title  \\\n",
       "38303  Evangelical Pastors Advise Trump: Why Are Chri...   \n",
       "8967   Will IMF Try to Stiff Russia for Ukraine Billi...   \n",
       "5033   'Pulimurugan' Malayalam movie review: live pub...   \n",
       "38193            Treating Prostate Cancer with Green Tea   \n",
       "29134                             Cable: 1973VIENNA08803   \n",
       "...                                                  ...   \n",
       "18585                                   ✿ nicolas_gent ✿   \n",
       "23357  Speculation Grows that Obama Will Announce His...   \n",
       "26069  Melania Trump Speech at Republican Convention ...   \n",
       "18006            What to do if CPS shows up at your door   \n",
       "24685  Teen Girls Pretend To Be Pregnant To Smuggle W...   \n",
       "\n",
       "                                                 authors keywords  \\\n",
       "38303                                                NaN      NaN   \n",
       "8967   Michael Hudson, Gilbert Doctorow, Charles Baus...      NaN   \n",
       "5033         Blasting News, Kendall Thomas, Hailey Jones      NaN   \n",
       "38193                          Michael Greger M.D. Faclm      NaN   \n",
       "29134                                                NaN      NaN   \n",
       "...                                                  ...      ...   \n",
       "18585                                                NaN      NaN   \n",
       "23357                                       Jason Easley      NaN   \n",
       "26069                                                NaN      NaN   \n",
       "18006  Erin Elizabeth, Wendy Perry Harding, Sara Szok...      NaN   \n",
       "24685                                                NaN      NaN   \n",
       "\n",
       "                                           meta_keywords  \\\n",
       "38303                                               ['']   \n",
       "8967                                     ['russia news']   \n",
       "5033                                                ['']   \n",
       "38193                                               ['']   \n",
       "29134                                               ['']   \n",
       "...                                                  ...   \n",
       "18585                                               ['']   \n",
       "23357                                               ['']   \n",
       "26069                                               ['']   \n",
       "18006  ['medical kidnap', 'health', 'rights', 'cps', ...   \n",
       "24685                                               ['']   \n",
       "\n",
       "                                        meta_description  \\\n",
       "38303  I'm extremely saddened by the negative comment...   \n",
       "8967   This is an excerpt from an article that origin...   \n",
       "5033   The Mohanlal, Kamalini Mukherjee and Jagapati ...   \n",
       "38193  Green tea is put to the test against precancer...   \n",
       "29134                                                NaN   \n",
       "...                                                  ...   \n",
       "18585                                                NaN   \n",
       "23357                                                NaN   \n",
       "26069                                                NaN   \n",
       "18006  We live in a society that sadly, necessitates ...   \n",
       "24685  Going to the movies is expensive. A group of t...   \n",
       "\n",
       "                                                    tags summary source  \\\n",
       "38303                                                NaN     NaN    NaN   \n",
       "8967                                                 NaN     NaN    NaN   \n",
       "5033   4218 followers Dragon Ball Super, Movies, 4062...     NaN    NaN   \n",
       "38193  liver health, black tea, men's health, Volume ...     NaN    NaN   \n",
       "29134                                          View Tags     NaN    NaN   \n",
       "...                                                  ...     ...    ...   \n",
       "18585                                                NaN     NaN    NaN   \n",
       "23357                 book review, news, Obama, NBC, ABC     NaN    NaN   \n",
       "26069                                                NaN     NaN    NaN   \n",
       "18006                                                NaN     NaN    NaN   \n",
       "24685                                                NaN     NaN    NaN   \n",
       "\n",
       "      type_id  \n",
       "38303       7  \n",
       "8967        0  \n",
       "5033        9  \n",
       "38193       7  \n",
       "29134      11  \n",
       "...       ...  \n",
       "18585       5  \n",
       "23357       1  \n",
       "26069       1  \n",
       "18006       5  \n",
       "24685       1  \n",
       "\n",
       "[38489 rows x 17 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> master
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.set_index('id', inplace = True)\n",
    "from sklearn.utils import shuffle\n",
    "train = shuffle(train, random_state = 1)\n",
    "test = shuffle(test, random_state = 1)\n",
    "train.reset_index(inplace = True, drop = True)\n",
    "test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'to', 'token']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how the tokenizer works\n",
    "list(tokenize(\"This , is 5to TOKEN\", lowercase = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
<<<<<<< HEAD
     "text": "CPU times: user 1.17 ms, sys: 20 µs, total: 1.19 ms\nWall time: 1.89 ms\n"
=======
     "output_type": "stream",
     "text": [
      "CPU times: user 783 µs, sys: 7 µs, total: 790 µs\n",
      "Wall time: 802 µs\n"
     ]
>>>>>>> master
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "series_content = train.content\n",
    "#contTok = series_content.apply(nltk.word_tokenize)\n",
    "typeLst = train.type_id.tolist()\n",
    "#np.unique(typeLst, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = test.content\n",
    "test_typeLst = test.type_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_content\n",
    "#test_typeLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try gensim tokenizer\n",
    "testTok = test_content.apply(tokenize,lowercase =True)\n",
    "for i in testTok.index:\n",
    "    testTok[i] = list(testTok[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try gensim tokenizer\n",
    "contTok = series_content.apply(tokenize,lowercase =True)\n",
    "for i in contTok.index:\n",
    "    contTok[i] = list(contTok[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe fallback tokenizer\n",
    "#contTok1 = series_content.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "'junksci'"
=======
      "text/plain": [
       "0        [are, you, prepared, for, the, coming, economi...\n",
       "1        [julius, caesar, is, reputed, to, have, said, ...\n",
       "2        [raw, content, confidential, page, state, orig...\n",
       "3        [the, vice, president, is, at, it, again, joe,...\n",
       "4        [geopolítica, guerra, fría, en, el, ártico, el...\n",
       "                               ...                        \n",
       "38484    [finally, the, day, has, arrived, the, god, da...\n",
       "38485    [stranger, things, season, arrives, on, netfli...\n",
       "38486    [below, is, an, approximation, of, this, video...\n",
       "38487    [belgium, has, recalled, all, experts, from, t...\n",
       "38488    [enron, s, india, disaster, by, sam, parry, de...\n",
       "Name: content, Length: 38489, dtype: object"
      ]
>>>>>>> master
     },
     "execution_count": 495,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 422
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "train.type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(contTok, [i]) for i, contTok in enumerate(contTok)]\n",
    "#contTok[291496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38489"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> master
   "source": [
    "#list(enumerate(contTok))[0]\n",
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Doc2Vec(documents, vector_size = 150, dm = 0, epochs=15, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
<<<<<<< HEAD
     "text": "CPU times: user 22min 15s, sys: 21 s, total: 22min 36s\nWall time: 10min 50s\n"
=======
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 7s, sys: 28.5 s, total: 22min 36s\n",
      "Wall time: 11min 52s\n"
     ]
>>>>>>> master
    }
   ],
   "source": [
    "%%time\n",
    "model1 = Doc2Vec(documents, vector_size = , min_count = 3, window = 10, epochs=10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eventuel træn andre modeller herefter:\n",
    "#%%time\n",
    "#model2 = Doc2Vec(documents, vector_size = 200, dm = 1, min_count = 3, window = 10, epochs= 10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "[('introverted', 0.3632413148880005),\n ('johansen', 0.32919424772262573),\n ('trick', 0.31969472765922546),\n ('bulge', 0.30862855911254883),\n ('parents', 0.306522011756897),\n ('inr', 0.30332380533218384),\n ('reflective', 0.3025538921356201),\n ('ducing', 0.30231982469558716),\n ('prolifera', 0.30203330516815186),\n ('dialogues', 0.3010951280593872)]"
=======
      "text/plain": [
       "[('samsung', 0.6107205152511597),\n",
       " ('ios', 0.5921568274497986),\n",
       " ('microsoft', 0.583616316318512),\n",
       " ('iphone', 0.5742916464805603),\n",
       " ('smartphone', 0.5690572261810303),\n",
       " ('smartphones', 0.5272736549377441),\n",
       " ('android', 0.5272537469863892),\n",
       " ('ipad', 0.5223880410194397),\n",
       " ('handset', 0.5197432041168213),\n",
       " ('появлении', 0.5081181526184082)]"
      ]
>>>>>>> master
     },
     "execution_count": 502,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 22
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.most_similar('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "51466"
=======
      "text/plain": [
       "38489"
      ]
>>>>>>> master
     },
     "execution_count": 45,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 23
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "[(47016, 0.7833322882652283),\n (39974, 0.7338676452636719),\n (41431, 0.7269080877304077),\n (2547, 0.7235113382339478),\n (9676, 0.7217190265655518),\n (39357, 0.7115262746810913),\n (45440, 0.7040430307388306),\n (18977, 0.6920127868652344),\n (30585, 0.6893031001091003),\n (5103, 0.6876428127288818)]"
=======
      "text/plain": [
       "[(19974, 0.6026570796966553),\n",
       " (6195, 0.5667001008987427),\n",
       " (8050, 0.5630171298980713),\n",
       " (25975, 0.5596201419830322),\n",
       " (15223, 0.5478417873382568),\n",
       " (12121, 0.5426212549209595),\n",
       " (14863, 0.5373646020889282),\n",
       " (6173, 0.5368658900260925),\n",
       " (35464, 0.5345829725265503),\n",
       " (32663, 0.5342726707458496)]"
      ]
>>>>>>> master
     },
     "execution_count": 503,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 24
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.docvecs.most_similar(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "39974    fake\nName: type, dtype: object"
=======
      "text/plain": [
       "19974    fake\n",
       "Name: type, dtype: object"
      ]
>>>>>>> master
     },
     "execution_count": 517,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 457
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "train.type.loc[train.type.index == 39974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.type.loc[train.index == 38424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['clickbait', 'junksci', 'political'], dtype=object), array([3, 4, 3]))"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "#See types of most similar documents for model2\n",
    "#for idx in train.type.loc[train.type == 'fake'].index:\n",
    "sim_labels1 = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels1)):\n",
    "    sim_labels1[i] = train.type.loc[train.type.index == model2.docvecs.most_similar(51398)[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels1,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "16       bias\n21       bias\n23       bias\n34       bias\n43       bias\n         ... \n51398    bias\n51399    bias\n51400    bias\n51416    bias\n51464    bias\nName: type, Length: 5600, dtype: object"
=======
      "text/plain": [
       "0        conspiracy\n",
       "16       conspiracy\n",
       "30       conspiracy\n",
       "31       conspiracy\n",
       "41       conspiracy\n",
       "            ...    \n",
       "38466    conspiracy\n",
       "38467    conspiracy\n",
       "38471    conspiracy\n",
       "38473    conspiracy\n",
       "38476    conspiracy\n",
       "Name: type, Length: 4000, dtype: object"
      ]
>>>>>>> master
     },
     "execution_count": 518,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 29
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "#Lookup indeices for articles with certain types\n",
    "train.type.loc[train.type == 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 traindata\n",
    "train_arrays = np.zeros((model1.docvecs.count,150),dtype=\"float32\")\n",
    "train_labels = np.zeros(model1.docvecs.count,dtype=\"float32\")\n",
    "for i in range(model1.docvecs.count):\n",
    "    train_arrays[i] = model1.docvecs[i]\n",
    "    train_labels[i] = train.type_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "51466"
=======
      "text/plain": [
       "3.0"
      ]
>>>>>>> master
     },
     "execution_count": 225,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 477
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 traindata:\n",
    "train_arrays2 = np.zeros((model2.docvecs.count,150),dtype=\"float32\")\n",
    "train_labels2 = np.zeros(model2.docvecs.count,dtype=\"float32\")\n",
    "for i in range(model2.docvecs.count):\n",
    "    train_arrays2[i] = model2.docvecs[i]\n",
    "    train_labels2[i] = train.type_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(train_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_arrays[0]\n",
    "#train_labels[0]\n",
    "#model1.docvecs.most_similar([train_arrays[0]])\n",
    "#train.loc[train.index == 37400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How infer_vector works:\n",
    "token = \"this is new sentence\".split()\n",
    "new_vector = model1.infer_vector(token)\n",
    "sims = model1.docvecs.most_similar([new_vector])\n",
    "#model2.docvecs.most_similar([new_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_vec = model2.infer_vector(contTok[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.docvecs.most_similar([new_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring vectors for testdata with model1\n",
    "test_arrays = np.zeros((len(test),150),dtype = \"float32\")\n",
    "for i in range(len(test)):\n",
    "    test_arrays[i] = model1.infer_vector(testTok[i],steps = 15)   \n",
    "test_labels = np.array(test_typeLst,dtype=\"float32\")\n",
    "\n",
    "#test_arrays = np.zeros((model1.docvecs.count,150),dtype=\"float32\")\n",
    "#test_labels = np.zeros(model1.docvecs.count,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 6min 29s, sys: 5.3 s, total: 6min 34s\nWall time: 6min 48s\n"
    }
   ],
   "source": [
    "%%time\n",
    "#Inferring vectors for testdata with model2\n",
    "test_arrays2 = np.zeros((len(test),150),dtype = \"float32\")\n",
    "for i in range(len(test)):\n",
    "    test_arrays2[i] = model2.infer_vector(testTok[i], epochs = 20, alpha = 0.025)   \n",
    "test_labels = np.array(test_typeLst,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testTok[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_labels[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32672, 0.5412675142288208),\n",
       " (10444, 0.5094727277755737),\n",
       " (23135, 0.49477219581604004),\n",
       " (5553, 0.4843190908432007),\n",
       " (33264, 0.4779159426689148),\n",
       " (32602, 0.4745362102985382),\n",
       " (460, 0.4699743688106537),\n",
       " (24024, 0.468875527381897),\n",
       " (11487, 0.4654442071914673),\n",
       " (2246, 0.46349072456359863)]"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.docvecs.most_similar([test_arrays[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "3642    clickbait\nName: type, dtype: object"
=======
      "text/plain": [
       "200    bias\n",
       "Name: type, dtype: object"
      ]
>>>>>>> master
     },
     "execution_count": 570,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 180
    }
   ],
   "source": [
    "test.type.loc[test.type.index == 3642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7e4e95c284f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msim_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msim_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "#Find originalarticle types most similar to inferred vector by model1:\n",
    "sim_labels = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels)):\n",
    "    sim_labels[i] = train.type.loc[train.type.index == model1.docvecs.most_similar([test_arrays[10]])[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "[(15221, 0.460197776556015),\n (20051, 0.4442721903324127),\n (37955, 0.4413350224494934),\n (6278, 0.4317403733730316),\n (17709, 0.4302103519439697),\n (29647, 0.42933136224746704),\n (19457, 0.4270772933959961),\n (122, 0.42285194993019104),\n (32331, 0.42190662026405334),\n (21916, 0.421882688999176)]"
=======
      "text/plain": [
       "(array(['bias', 'conspiracy', 'hate', 'political', 'reliable'],\n",
       "       dtype=object), array([3, 2, 2, 2, 1]))"
      ]
>>>>>>> master
     },
     "execution_count": 569,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 350
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.docvecs.most_similar([test_arrays2[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "'satire'"
=======
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
>>>>>>> master
     },
     "execution_count": 576,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 49
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "train.type[10004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "[(14004, 0.6460142731666565),\n (31820, 0.6411257982254028),\n (36654, 0.6238328218460083),\n (10004, 0.6183276176452637),\n (4258, 0.612575113773346),\n (9671, 0.6100050210952759),\n (45557, 0.6094460487365723),\n (36745, 0.6056312322616577),\n (46957, 0.6026122570037842),\n (12744, 0.6022600531578064)]"
=======
      "text/plain": [
       "0.4786449132287229"
      ]
>>>>>>> master
     },
     "execution_count": 571,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 45
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "model2.docvecs.most_similar([test_arrays2[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['clickbait', 'political', 'reliable'], dtype=object), array([1, 2, 7]))"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "#Find originalarticle types most similar to inferred vector by model2:\n",
    "sim_labels = np.empty(10,dtype='object')\n",
    "for i in range(len(sim_labels)):\n",
    "    sim_labels[i] = train.type.loc[train.type.index == model2.docvecs.most_similar([test_arrays2[75]])[i][0]].values[0]\n",
    "\n",
    "np.unique(sim_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([   11,    17,    25,    29,    54,    63,    75,    88,    90,\n              124,\n            ...\n            12742, 12748, 12762, 12784, 12803, 12816, 12818, 12826, 12851,\n            12866],\n           dtype='int64', length=1045)"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "#Get indices for testarticles of a certain type:\n",
    "test.type.loc[test.type == 'reliable'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.docvecs.most_similar([test_arrays[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.type.loc[train.type == 'bias'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_arrays2)\n",
    "X_train = scaler.transform(train_arrays2)\n",
    "X_test = scaler.transform(test_arrays2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "2489"
=======
      "text/plain": [
       "array([[120, 175, 162,  83,  93,  55,  93,  92,  80,  47],\n",
       "       [  7, 532,  96,  27,  13,  49,  84,  81,  96,  15],\n",
       "       [ 23, 124, 427,  92,  40,  76,  78,  51,  71,  18],\n",
       "       [ 10, 104, 183, 260,  33, 141,  89,  45, 112,  23],\n",
       "       [ 10,  86,  84,  31, 262,  27,  38,  46,  23,  16],\n",
       "       [  3, 115, 121,  42,   1, 639,  10,  27,  38,   4],\n",
       "       [ 14, 197, 133,  75,  40,  46, 301,  79,  95,  20],\n",
       "       [ 17, 142,  44,  25,  34,  62,  38, 564,  61,  13],\n",
       "       [  5, 107,  64,  31,  19,  48,  33,  26, 652,  15],\n",
       "       [  7,  45,  15,  15,   3,  18,  20,  12,  16, 849]])"
      ]
>>>>>>> master
     },
     "execution_count": 586,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 411
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "len(train.loc[train.type == 'hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "1.6070711128967456"
=======
      "text/plain": [
       "0.4786449132287229"
      ]
>>>>>>> master
     },
     "execution_count": 587,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 405
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "4000/2489\n",
    "2489/400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=None, penalty='l2',\n                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n                   warm_start=True)"
=======
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
>>>>>>> master
     },
     "execution_count": 588,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 527
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "#Now train a logistic classifier:\n",
    "#can try gridsearch for parameters:\n",
    "#Logistic = LogisticRegression()\n",
    "#grid = {\"C\" :np.logspace(0,4,10), \"penalty\": [\"l1\", \"l2\"]}\n",
    "#logClf = GridSearchCV(Logistic, grid, cv = 5)\n",
    "#best_model = logClf.fit(X_train, train_labels)\n",
    "clfLog = LogisticRegression(C = 0.01,multi_class = 'multinomial', solver = 'saga', penalty = 'l2', warm_start = True)\n",
    "clfLog.fit(X_train, train_labels2)\n",
    "\n",
    "#classifier.fit(X_train,train_labels)\n",
    "#classifier.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "0.6565899906745415"
=======
      "text/plain": [
       "0.3837680556998857"
      ]
>>>>>>> master
     },
     "execution_count": 330,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 528
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "clfLog.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_labels\n",
    "#y_true\n",
    "y_pred = clfLog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "array([[433,  59,  96,  13, 160,  49, 109,  45,  30,   6],\n       [ 50, 546,  49,  12,  51,  42, 119,  51,  72,   8],\n       [ 75,  60, 530,  14,  82,  63, 105,  22,  43,   6],\n       [ 15,  18,  33, 852,  15,  33,  17,   5,  11,   1],\n       [ 39,  38,  28,   8, 415,  11,  44,  21,  14,   5],\n       [ 22,  41,  41,   7,  11, 807,  15,  21,  35,   0],\n       [ 93, 137,  76,  14,  76,  22, 468,  58,  50,   6],\n       [ 63,  64,  16,   5,  51,  25,  46, 692,  37,   1],\n       [ 39,  79,  49,   8,  34,  31,  56,  18, 682,   4],\n       [ 18,  40,  18,   4,  11,  11,  27,   9,   8, 854]])"
=======
      "text/plain": [
       "array([[455, 106, 134,  91,  24,  27, 101,  16,  31,   9],\n",
       "       [ 72, 583,  41,  92,  12,  23,  77,  45,  37,   5],\n",
       "       [153, 132, 495,  84,   8,  36,  74,   8,  20,   3],\n",
       "       [ 86, 115, 108, 472,   6,  56,  80,  16,  57,   4],\n",
       "       [ 51,  67,  30,  39, 155,  11,  54,  13,   5,   4],\n",
       "       [ 37, 220,  77,  79,   4, 513,  31,   8,  12,   2],\n",
       "       [ 86, 153,  82,  57,   6,  18, 448,  39,  34,   2],\n",
       "       [ 41,  86,  12,  40,   8,   3,  61, 455,  31,   1],\n",
       "       [ 47,  67,  32,  93,   2,  35,  44,  15, 642,   3],\n",
       "       [ 33,  41,  22,  23,   2,   8,  31,   8,  11, 779]])"
      ]
>>>>>>> master
     },
     "execution_count": 458,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 415
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "0.6406526031383144"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>452168</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/gold-and-precious-met...</td>\n",
       "      <td>Agriculture Is Going To Be Extremely Profitabl...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Agriculture Is Going To Be Extremely Profitabl...</td>\n",
       "      <td>Jim Rogers Blog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>787933</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/green-living/2013/02/...</td>\n",
       "      <td>Buried in Snow: Nemo Found Us\\n\\nHeadline: Bit...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Buried in Snow: Nemo Found Us</td>\n",
       "      <td>Groovy Green Livin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>806045</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/health/2012/06/autism...</td>\n",
       "      <td>Autism Signs Found In Fish Due To Big-Pharma\\n...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Autism Signs Found In Fish Due To Big-Pharma</td>\n",
       "      <td>Alan Freestone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>831732</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/outdoors/2011/12/book...</td>\n",
       "      <td>Book Review: 10: Celebrating Ten Years of the ...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Book Review: 10: Celebrating Ten Years of the ...</td>\n",
       "      <td>The Adventure Blog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>776101</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/alternative/2013/02/e...</td>\n",
       "      <td>evening of insight and truth into the Pope &amp; t...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>evening of insight and truth into the Pope &amp; t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4895</td>\n",
       "      <td>431227</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/celebrities/2010/08/y...</td>\n",
       "      <td>Yes, THAT Eli Wallach\\n\\n% of readers think th...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Yes, THAT Eli Wallach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4896</td>\n",
       "      <td>810336</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/forex/2011/08/euro-ex...</td>\n",
       "      <td>Euro Extending Losses; SNB Intervention Just A...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Euro Extending Losses; SNB Intervention Just A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EURJPY, AUDJPY, Silver, CHFJPY, EURAUD, EURUSD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4897</td>\n",
       "      <td>1029673</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/eu/2013/02/salafists-...</td>\n",
       "      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Salafists fail to stop ‘Harlem Shake’ in Tunisia</td>\n",
       "      <td>Vlad Tepes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4898</td>\n",
       "      <td>458467</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/politics/2013/09/more...</td>\n",
       "      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>More opposition to Energy East</td>\n",
       "      <td>The Media Co-Op</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4899</td>\n",
       "      <td>28790</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>Caeneus Minerals raises funds for lithium in C...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Caeneus Minerals raises funds for lithium in C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             domain  type  \\\n",
       "0      452168  beforeitsnews.com  fake   \n",
       "1      787933  beforeitsnews.com  fake   \n",
       "2      806045  beforeitsnews.com  fake   \n",
       "3      831732  beforeitsnews.com  fake   \n",
       "4      776101  beforeitsnews.com  fake   \n",
       "...       ...                ...   ...   \n",
       "4895   431227  beforeitsnews.com  fake   \n",
       "4896   810336  beforeitsnews.com  fake   \n",
       "4897  1029673  beforeitsnews.com  fake   \n",
       "4898   458467  beforeitsnews.com  fake   \n",
       "4899    28790  beforeitsnews.com  fake   \n",
       "\n",
       "                                                    url  \\\n",
       "0     http://beforeitsnews.com/gold-and-precious-met...   \n",
       "1     http://beforeitsnews.com/green-living/2013/02/...   \n",
       "2     http://beforeitsnews.com/health/2012/06/autism...   \n",
       "3     http://beforeitsnews.com/outdoors/2011/12/book...   \n",
       "4     http://beforeitsnews.com/alternative/2013/02/e...   \n",
       "...                                                 ...   \n",
       "4895  http://beforeitsnews.com/celebrities/2010/08/y...   \n",
       "4896  http://beforeitsnews.com/forex/2011/08/euro-ex...   \n",
       "4897  http://beforeitsnews.com/eu/2013/02/salafists-...   \n",
       "4898  http://beforeitsnews.com/politics/2013/09/more...   \n",
       "4899  http://beforeitsnews.com/financial-markets/201...   \n",
       "\n",
       "                                                content  \\\n",
       "0     Agriculture Is Going To Be Extremely Profitabl...   \n",
       "1     Buried in Snow: Nemo Found Us\\n\\nHeadline: Bit...   \n",
       "2     Autism Signs Found In Fish Due To Big-Pharma\\n...   \n",
       "3     Book Review: 10: Celebrating Ten Years of the ...   \n",
       "4     evening of insight and truth into the Pope & t...   \n",
       "...                                                 ...   \n",
       "4895  Yes, THAT Eli Wallach\\n\\n% of readers think th...   \n",
       "4896  Euro Extending Losses; SNB Intervention Just A...   \n",
       "4897  Headline: Bitcoin & Blockchain Searches Exceed...   \n",
       "4898  Headline: Bitcoin & Blockchain Searches Exceed...   \n",
       "4899  Caeneus Minerals raises funds for lithium in C...   \n",
       "\n",
       "                      scraped_at                 inserted_at  \\\n",
       "0     2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "1     2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "2     2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "3     2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "4     2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "...                          ...                         ...   \n",
       "4895  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "4896  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "4897  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "4898  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "4899  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                      updated_at  \\\n",
       "0     2018-02-02 01:19:41.756664   \n",
       "1     2018-02-02 01:19:41.756664   \n",
       "2     2018-02-02 01:19:41.756664   \n",
       "3     2018-02-02 01:19:41.756664   \n",
       "4     2018-02-02 01:19:41.756664   \n",
       "...                          ...   \n",
       "4895  2018-02-02 01:19:41.756664   \n",
       "4896  2018-02-02 01:19:41.756664   \n",
       "4897  2018-02-02 01:19:41.756664   \n",
       "4898  2018-02-02 01:19:41.756664   \n",
       "4899  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                  title             authors  \\\n",
       "0     Agriculture Is Going To Be Extremely Profitabl...     Jim Rogers Blog   \n",
       "1                         Buried in Snow: Nemo Found Us  Groovy Green Livin   \n",
       "2          Autism Signs Found In Fish Due To Big-Pharma      Alan Freestone   \n",
       "3     Book Review: 10: Celebrating Ten Years of the ...  The Adventure Blog   \n",
       "4     evening of insight and truth into the Pope & t...                 NaN   \n",
       "...                                                 ...                 ...   \n",
       "4895                              Yes, THAT Eli Wallach                 NaN   \n",
       "4896  Euro Extending Losses; SNB Intervention Just A...                 NaN   \n",
       "4897   Salafists fail to stop ‘Harlem Shake’ in Tunisia          Vlad Tepes   \n",
       "4898                     More opposition to Energy East     The Media Co-Op   \n",
       "4899  Caeneus Minerals raises funds for lithium in C...                 NaN   \n",
       "\n",
       "     keywords meta_keywords meta_description  \\\n",
       "0         NaN          ['']              NaN   \n",
       "1         NaN          ['']              NaN   \n",
       "2         NaN          ['']              NaN   \n",
       "3         NaN          ['']              NaN   \n",
       "4         NaN          ['']              NaN   \n",
       "...       ...           ...              ...   \n",
       "4895      NaN          ['']              NaN   \n",
       "4896      NaN          ['']              NaN   \n",
       "4897      NaN          ['']              NaN   \n",
       "4898      NaN          ['']              NaN   \n",
       "4899      NaN          ['']              NaN   \n",
       "\n",
       "                                                   tags summary source  \\\n",
       "0                                                   NaN     NaN    NaN   \n",
       "1                                                   NaN     NaN    NaN   \n",
       "2                                                   NaN     NaN    NaN   \n",
       "3                                                   NaN     NaN    NaN   \n",
       "4                                                   NaN     NaN    NaN   \n",
       "...                                                 ...     ...    ...   \n",
       "4895                                                NaN     NaN    NaN   \n",
       "4896  EURJPY, AUDJPY, Silver, CHFJPY, EURAUD, EURUSD...     NaN    NaN   \n",
       "4897                                                NaN     NaN    NaN   \n",
       "4898                                                NaN     NaN    NaN   \n",
       "4899                                                NaN     NaN    NaN   \n",
       "\n",
       "      type_id  \n",
       "0           3  \n",
       "1           3  \n",
       "2           3  \n",
       "3           3  \n",
       "4           3  \n",
       "...       ...  \n",
       "4895        3  \n",
       "4896        3  \n",
       "4897        3  \n",
       "4898        3  \n",
       "4899        3  \n",
       "\n",
       "[4900 rows x 17 columns]"
      ]
>>>>>>> master
     },
     "execution_count": 461,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 287
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 530
    }
   ],
   "source": [
    "#Try GaussianNB:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clfNB = GaussianNB()\n",
    "clfNB.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5231582219459123"
     },
     "metadata": {},
     "execution_count": 531
    }
   ],
   "source": [
    "clfNB.score(X_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0)"
=======
      "text/plain": [
       "[('solid', 0.5569016933441162),\n",
       " ('weak', 0.48024940490722656),\n",
       " ('positive', 0.4619835615158081),\n",
       " ('significant', 0.4544695019721985),\n",
       " ('low', 0.44241464138031006),\n",
       " ('powerful', 0.4360508918762207),\n",
       " ('large', 0.42998695373535156),\n",
       " ('tough', 0.4249303936958313),\n",
       " ('high', 0.4169711470603943),\n",
       " ('broad', 0.4161904752254486)]"
      ]
>>>>>>> master
     },
     "execution_count": 454,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 252
=======
     "output_type": "execute_result"
>>>>>>> master
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LinSvm = LinearSVC()\n",
    "LinSvm.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6350410474903876"
     },
     "metadata": {},
     "execution_count": 253
    }
   ],
   "source": [
    "LinSvm.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 532
    }
   ],
   "source": [
    "#rbf kernel = 0 .72, poly kernel = 0.7\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#parameters = {'C':[1,10], 'kernel': ('linear','rbf')}\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,train_labels2)\n",
    "#clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7192259869443581"
     },
     "metadata": {},
     "execution_count": 533
    }
   ],
   "source": [
    "clf.score(X_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[603,  51,  73,  23,  50,  27, 106,  33,  34,   0],\n       [101, 614,  37,  15,  13,  24,  97,  38,  61,   0],\n       [117,  50, 578,  40,  34,  42,  98,   5,  34,   2],\n       [ 17,  10,  25, 890,   5,  22,  19,   5,   7,   0],\n       [ 81,  24,  31,  15, 382,   8,  54,  16,  11,   1],\n       [ 31,  34,  45,  17,   5, 824,  12,   7,  24,   1],\n       [173,  92,  72,  28,  27,  18, 501,  31,  57,   1],\n       [ 42,  37,  13,   4,   8,   7,  33, 829,  27,   0],\n       [ 58,  46,  25,  25,  11,  24,  41,  12, 755,   3],\n       [ 21,  47,   8,   3,   6,   8,  21,   7,   9, 870]])"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred_svm)\n",
    "#np.unique(train_labels2 == typeLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')"
     },
     "metadata": {},
     "execution_count": 534
    }
   ],
   "source": [
    "#Decicion tree\n",
    "from sklearn import tree\n",
    "\n",
    "treeClf = tree.DecisionTreeClassifier()\n",
    "treeClf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.2661641280696301"
     },
     "metadata": {},
     "execution_count": 543
    }
   ],
   "source": [
    "treeClf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of labels=38489 does not match number of samples=51466",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-a8d6210465ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mforestClf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mforestClf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 250\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=38489 does not match number of samples=51466"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forestClf = RandomForestClassifier()\n",
    "forestClf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.35708734846129936"
     },
     "metadata": {},
     "execution_count": 542
    }
   ],
   "source": [
    "forestClf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_clf.fit(X_train, train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5564792684194119"
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "KNN_clf.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  9., 11.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 605
    }
   ],
   "source": [
    "np.unique(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[252, 131, 121,  46, 244,  63, 101,  28,  12,   2],\n       [ 27, 504,  69,  19,  99,  87, 103,  67,  23,   2],\n       [ 54, 102, 408,  54, 186,  81,  79,  15,  21,   0],\n       [ 30,  89, 150, 266, 181, 124,  92,  19,  44,   5],\n       [ 11,  50,  63,  13, 422,  21,  25,  13,   5,   0],\n       [  8,  55,  68,  20, 130, 691,  18,   8,   2,   0],\n       [ 40, 186,  94,  38, 182,  46, 363,  32,  18,   1],\n       [ 25,  79,  13,  10, 178,  54,  35, 591,  15,   0],\n       [ 16, 119,  50,  67,  83,  63,  78,  43, 474,   7],\n       [ 11,  46,  14,   9, 167,  15,  22,   6,   3, 707]])"
     },
     "metadata": {},
     "execution_count": 593
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try tf-idf svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(train[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scikit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "clf_NB = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('NB', MultinomialNB()),])\n",
    "                   \n",
    "# Support vector machine\n",
    "clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('svm', SGDClassifier()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.fit(series_content,typeLst )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([ True]), array([9623]))"
     },
     "metadata": {},
     "execution_count": 631
    }
   ],
   "source": [
    "np.unique(test_labels == test_typeLst, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7225397485191728"
     },
     "metadata": {},
     "execution_count": 646
    }
   ],
   "source": [
    "clf_svm.score(test_content, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-645-bc1c4179375a>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-645-bc1c4179375a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    clf_svm.score(test_content, test_labels)clf_svm.score(test_content, test_labels)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "clf_svm.score(test_content, test_labels)clf_svm.score(test_content, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 585
    }
   ],
   "source": [
    "#X_train\n",
    "#len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "51466"
     },
     "metadata": {},
     "execution_count": 589
    }
   ],
   "source": [
    "train_labels2 = np.array(train_labels2)\n",
    "len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train)\n",
    "#len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# laver modellen\n",
    "model = tf.keras.models.Sequential()\n",
    "# tilføjer et input på modellen\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# relu er default aktiverings funktion. Lav den om hvis resultatet ikke er godt nok\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "# jeg tilføjer 2 lag til netwærket. Dette er fordi det er en simpel opgave\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "\n",
    "#antallet (10) er antal output. Det er 10 tal i datasettet derfor skal der være et 10 tal\n",
    "model.add(tf.keras.layers.Dense(12, activation=tf.nn.softmax))\n",
    "\n",
    "# Dette er den mest komplexe del. adam er goto. Hvis der kun er 2 løsninger så brug binary_categorical_crossentropy eller binary_crossentropy i stedet for sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 1.3027029 ,  0.68641615, -1.5785896 , -1.0994292 ,  0.04590863,\n       -0.2966616 ,  0.9771466 ,  0.21622235, -0.3470798 ,  3.1173131 ,\n       -0.1263595 , -0.73402375,  1.2696388 , -2.126827  , -0.9250945 ,\n       -0.3924918 , -0.37099725,  1.7715138 , -1.4410161 , -1.975255  ,\n        0.5496809 , -1.2748119 , -0.8177417 ,  0.02426461,  0.9893084 ,\n        1.1830812 ,  0.41776237, -1.1550455 , -4.010288  , -0.62849367,\n        1.9609251 ,  1.7842555 ,  0.07232279,  0.08652694, -0.26362988,\n        0.40431616,  0.37941206, -0.4358795 ,  1.9571117 , -0.1995615 ,\n        2.3345501 ,  2.7220852 , -0.7210764 , -0.9317727 , -0.06868886,\n        0.1815532 ,  0.7272655 , -0.38696575,  0.33161533,  1.3247447 ,\n        0.3976764 ,  2.0253289 ,  0.36689404, -0.12554865,  0.40340206,\n        1.2147293 , -0.45223093, -0.27562487,  1.1727579 , -0.30993453,\n        0.1756779 ,  1.2397557 ,  1.8287936 ,  0.674076  ,  0.9979131 ,\n        0.20928827,  1.4333205 ,  0.5503944 ,  0.72474855,  0.24843858,\n        1.4945508 ,  0.14377834,  1.0856051 ,  1.4785489 , -0.37625724,\n       -1.5014796 , -0.06778135,  0.38143146, -0.20845814,  0.8330765 ,\n       -1.2574366 ,  0.15021512,  0.326662  , -0.1519804 , -0.75318396,\n       -0.50960356, -0.25695252,  1.1866256 , -0.53721917, -0.30860507,\n        0.61024094, -1.1223452 , -1.5706742 ,  0.96140563, -0.7556812 ,\n        0.59312797,  0.15536775,  0.45094398, -1.0978308 ,  1.0192091 ,\n       -2.1820018 , -0.03361591,  0.8614685 , -0.83699167,  0.36489442,\n        1.8966261 , -2.1867132 , -1.3728373 , -0.5332    , -0.24424617,\n        0.6027193 , -0.8612119 , -0.21818547, -0.9338229 , -1.3399721 ,\n        1.7833984 ,  0.03205905, -1.4845914 , -0.7260104 ,  0.84800947,\n        0.57359374,  1.0132505 , -2.9268441 ,  0.88682777,  1.571034  ,\n       -0.2611724 ,  0.1217367 ,  0.49585223,  0.25931165, -0.5345446 ,\n       -0.5672025 , -3.5191522 ,  1.7405412 ,  0.13712117,  0.87833905,\n        1.9746091 , -1.4628874 , -1.5220187 ,  0.3196786 ,  0.533711  ,\n       -0.69367296, -0.19808799,  1.7048742 , -2.3405898 , -1.0152365 ,\n        1.239305  , -0.36124048,  0.3563259 ,  0.61697036, -0.28903842],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/3\n1609/1609 [==============================] - 5s 3ms/step - loss: 1.8646 - accuracy: 0.3420\nEpoch 2/3\n1609/1609 [==============================] - 4s 3ms/step - loss: 1.3896 - accuracy: 0.5305\nEpoch 3/3\n1609/1609 [==============================] - 5s 3ms/step - loss: 1.2958 - accuracy: 0.5623\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x268e09950>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "model.fit(train_arrays2, train_labels2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "2.7.16-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
=======
   "version": "3.7.4"
>>>>>>> master
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
