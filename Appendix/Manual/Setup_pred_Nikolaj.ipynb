{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and creating df (has to have type_id)\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "filepath = '/Users/Master/Documents/KU/2.Semester/Datascience/news_sample.csv' #\n",
    "#s = 250                                            # desired sample size\n",
    "#seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_csv(filepath, index_col = [0])\n",
    "content = df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      Sometimes the power of Christmas will make you...\n1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...\n2      Never Hike Alone: A Friday the 13th Fan Film U...\n3      When a rare shark was caught, scientists were ...\n4      Donald Trump has the unnerving ability to abil...\n                             ...                        \n245    Prison for Rahm, God’s Work And Many Others\\n\\...\n246    4 Useful Items for Your Tiny Home\\n\\nHeadline:...\n247    Former CIA Director Michael Hayden said Thursd...\n248    Antonio Sabato Jr. says Hollywood's liberal el...\n249    Former U.S. President Bill Clinton on Monday c...\nName: content, Length: 250, dtype: object"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"these word are features\")\n",
    "with nlp.disable_pipes():\n",
    "    vectors = np.array([token.vector for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "these\nword\n,\nare\nfeatures\n"
    }
   ],
   "source": [
    "doc = nlp(\"these word, are features\")\n",
    "for token in doc:\n",
    "    print(token)\n",
    "#token.lemma_\n",
    "#token.is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipes():\n",
    "    doc_vectors = np.array([nlp(sentence).vector for sentence in df['content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeidx = df.index[df.type == 'fake'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakevecs = np.array([doc_vectors[i] for i in fakeidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.442973"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "\n",
    "len(fakevecs)\n",
    "np.linalg.norm(fakevecs[0])\n",
    "#calc avg vector of the type-vectors:\n",
    "#np.linalg.norm(fakevecs[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type.fillna('no type', inplace = True)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(doc_vectors, df.type, test_size = 0.1, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nlp('REPLY NOW FOR FREE TEA').vector\n",
    "b = nlp('REPLY NOW FOR FREE TEA AND Potatoes').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 64.000%\n"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state = 1, dual = False, max_iter = 10000)\n",
    "svc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {svc.score(X_test, y_test) * 100:.3f}%\",)\n",
    "#svc.score(X_test,y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.metrics.pairwise.cosine_similarity(a,b)\n",
    "def cosine_similarity(a,b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.95132565"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "cosine_similarity(fakevecs[152],doc_vectors[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try tf-idf svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, df.type, test_size = 0.1, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.52"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.40884613016820903\n1.0\n"
    }
   ],
   "source": [
    "x = nlp(\"man\")\n",
    "y = nlp(\"king\")\n",
    "print(x.similarity(y))\n",
    "print(x.similarity(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec \n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_id'] = df.groupby(['type']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "series_content = df.content\n",
    "\n",
    "contTok =series_content.str.split().tolist()\n",
    "typeLst =df.type_id.tolist()\n",
    "\n",
    "#doc1 = [\"This is a sentence\", \"This is another sentence\"]\n",
    "#docs = []\n",
    "#analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "#for i, text in enumerate(doc1):\n",
    "#    words = text.lower().split()\n",
    "#    tags = [i]\n",
    "#    docs.append(analyzedDocument(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Doc2Vec(docs, size = 100, window = 300, min_count = 1, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.models.doc2vec.Doc2Vec(vector_size=250, min_count=2, epochs=40)\n",
    "#documents = [TaggedDocument(contTok,df.index) for sentence in df]\n",
    "documents = [TaggedDocument(contTok, [i]) for i, contTok in enumerate(contTok)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size = 250, min_count = 2, epochs= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "#doc2 = nlp(df.content[20])v\n",
    "#tokdoc2 = [token for token in nlp(df.content[20])] \n",
    "#for token in doc2:\n",
    "#    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.infer_vector(['trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'clickbait'"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "df.type[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(196, 0.854720950126648),\n (83, 0.7812755703926086),\n (239, 0.7757385969161987),\n (4, 0.7741408348083496),\n (192, 0.7681198716163635),\n (128, 0.7517058849334717),\n (74, 0.734205961227417),\n (110, 0.7236354351043701),\n (66, 0.706433117389679),\n (15, 0.704484224319458)]"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "sim_doc = model.docvecs.most_similar([12])\n",
    "sim_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df.type == 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-6669bda1078e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontTok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, indexer)\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1728\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1729\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_docs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                 \u001b[0mall_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "print(model.docvecs.most_similar(contTok[80]))\n",
    "model.docvecs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Offers are getting into the six-figure range in pre-bidding for the NamesCon live auction\\n\\nHeadline: Bitcoin & Blockchain Searches Exceed Trump! Blockchain Stocks Are Next!\\n\\nIn a few weeks domain name investors from around the world will converge in Las Vegas for NamesCon, the largest event in the domain industry. One of the highlights of the conference is the live domain auction hosted by ROTD and pre-bidding has already started on NameJet, and like the title says, there are already six-figure bids.\\n\\nIf you’ve never been to a live domain auction I can tell you – it’s a rush that’s hard to explain, at least for a domain geek like me. Monte Cahn, one of the most respected domain industry veterans will be running the auction again this year and from what I’ve seen over the years, when Monte’s involved, a lot of the truly premium domains come out.\\n\\nSo I’m not incredibly surprised that we’re already starting to see six-figure bids come out in pre-bidding more than two weeks before the auction. The two domains with six-figure bids are:\\n\\nOther notable domains with strong interest in the pre-bidding phase are: pen.com, profile.com, shock.com, price.com, stop.com, cork.com, and the list goes on. I think it’s safe to say that some of the best one-word .COMs out there are going to hit the open market during the live auction at NamesCon this year.\\n\\nGiven that last year even two-word .COMs like MyWorld.com broke the $1M mark I think it’s safe to say this is likely going to be one of the most exciting live auctions yet. As usual I’ve submitted a handful of names to the auction and I’ll be interested to see which ones make the cut.\\n\\nOne strange thing I’ve learned about myself is that for some reason, when I’m in a live auction I end up with a rum and coke in my hand. Honestly I pretty much never drink rum and coke, it’s one of my least favorite drinks, but years ago I started drinking them during live auctions and now it’s become a bit of a tradition. If any of my readers are going to be at NamesCon, feel free to join me for one, maybe you can start a new tradition yourself!\\n\\nYou can see the full list of domains in pre-bidding for the NamesCon auction here.\\n\\nSource: http://morganlinton.com/offers-are-getting-into-the-six-figure-range-in-pre-bidding-for-the-namescon-live-auction/'"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "df.content[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}