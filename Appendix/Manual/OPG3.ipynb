{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execQuery(query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"postgress\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>inserted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13842</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://beforeitsnews.com/military/2017/12/russ...</td>\n",
       "      <td>['russia', 'responds', 'to', 'us', 'provocatio...</td>\n",
       "      <td>Russia Responds to US Provocation: Open Skies ...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2350</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>http://breakpoint.org/category/signs-and-wonde...</td>\n",
       "      <td>['signs', 'and', 'wondersr', 'r', 'snap', 'out...</td>\n",
       "      <td>Signs and Wonders Archives</td>\n",
       "      <td>['']</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27373</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.undergroundhealth.com/understandin...</td>\n",
       "      <td>['by', 'giovani', '', '', 'URL', 'r', 'r', 'ar...</td>\n",
       "      <td>Understanding What Authentic Happiness Is</td>\n",
       "      <td>['']</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.alternet.org/activism/if-we-dont-a...</td>\n",
       "      <td>['if', 'we', 'dont', 'act', 'now', 'fascism', ...</td>\n",
       "      <td>If We Don't Act Now, Fascism Will Be on Our Do...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6045</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://beforeitsnews.com/opinion-conservative/...</td>\n",
       "      <td>['greg', 'hunter', 'big', 'banks', 'in', 'big'...</td>\n",
       "      <td>Greg Hunter: Big Banks in Big Trouble, Syria/N...</td>\n",
       "      <td>['']</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  domain_id  type_id  \\\n",
       "0  13842          1        1   \n",
       "1   2350          2        2   \n",
       "2  27373          3        3   \n",
       "3  26536          0        0   \n",
       "4   6045          1        1   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://beforeitsnews.com/military/2017/12/russ...   \n",
       "1  http://breakpoint.org/category/signs-and-wonde...   \n",
       "2  https://www.undergroundhealth.com/understandin...   \n",
       "3  https://www.alternet.org/activism/if-we-dont-a...   \n",
       "4  http://beforeitsnews.com/opinion-conservative/...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ['russia', 'responds', 'to', 'us', 'provocatio...   \n",
       "1  ['signs', 'and', 'wondersr', 'r', 'snap', 'out...   \n",
       "2  ['by', 'giovani', '', '', 'URL', 'r', 'r', 'ar...   \n",
       "3  ['if', 'we', 'dont', 'act', 'now', 'fascism', ...   \n",
       "4  ['greg', 'hunter', 'big', 'banks', 'in', 'big'...   \n",
       "\n",
       "                                               title meta_description  \\\n",
       "0  Russia Responds to US Provocation: Open Skies ...             ['']   \n",
       "1                         Signs and Wonders Archives             ['']   \n",
       "2          Understanding What Authentic Happiness Is             ['']   \n",
       "3  If We Don't Act Now, Fascism Will Be on Our Do...             ['']   \n",
       "4  Greg Hunter: Big Banks in Big Trouble, Syria/N...             ['']   \n",
       "\n",
       "   scraped_at  updated_at inserted_at  \n",
       "0  2018-01-25  2018-02-02  2018-02-02  \n",
       "1  2018-01-25  2018-02-02  2018-02-02  \n",
       "2  2018-01-25  2018-02-02  2018-02-02  \n",
       "3  2018-01-25  2018-02-02  2018-02-02  \n",
       "4  2018-01-25  2018-02-02  2018-02-02  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load dataset\n",
    "connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\")\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "filepath = '../Data_git_ignore/clean_csv/article_clean.csv' # 250 rows of FakeNewsCorpus\n",
    "s = 250                                            # desired sample size\n",
    "seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM fakenews.article\", connection)\n",
    "#df[\"content\"] = df[\"content\"].astype(str)\n",
    "# c*reate type_id\n",
    "#df['type_id'] = df.groupby(['type']).ngroup()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "\n",
    "df['content'] = df['content'].apply(' '.join)\n",
    "\n",
    "x = v.fit_transform(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x.toarray(), df[\"type_id\"], test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laver modellen\n",
    "model = tf.keras.models.Sequential()\n",
    "# tilføjer et input på modellen\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# relu er default aktiverings funktion. Lav den om hvis resultatet ikke er godt nok\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "# jeg tilføjer 2 lag til netwærket. Dette er fordi det er en simpel opgave\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "\n",
    "#antallet (10) er antal output. Det er 10 tal i datasettet derfor skal der være et 10 tal\n",
    "model.add(tf.keras.layers.Dense(11, activation=tf.nn.softmax))\n",
    "\n",
    "# Dette er den mest komplexe del. adam er goto. Hvis der kun er 2 løsninger så brug binary_categorical_crossentropy eller binary_crossentropy i stedet for sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 0s 239us/sample - loss: 2.3750 - accuracy: 0.5400\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 0s 120us/sample - loss: 2.3686 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 0s 139us/sample - loss: 2.3618 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22581e9c3c8>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 90us/sample - loss: 2.3733 - accuracy: 0.4550\n",
      "2.373314743041992 0.455\n"
     ]
    }
   ],
   "source": [
    "# dette for for at trække om modellen er overfittet. val_loss og val_acc skal minde meget om det man får i fittet. \n",
    "#Det er ok at loss og acc er lidt højre på testen. De må ikke være fortæt eller for længt væk fra hinaden\n",
    "val_loss, val_acc = model.evaluate(X_test,y_test.values)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
