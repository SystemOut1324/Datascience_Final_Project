{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execQuery(query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"postgress\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>inserted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>437287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>['got', 'plans', 'saturday', 'of', 'readers', ...</td>\n",
       "      <td>Got Plans Saturday?</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>929199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.christianpost.com/news/birth-of-a-...</td>\n",
       "      <td>['the', 'views', 'expressed', 'by', 'the', 'au...</td>\n",
       "      <td>Birth of a Muslim Zionist</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>433367</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>['headline', 'bitcoin', 'blockchain', 'searche...</td>\n",
       "      <td>Fed to manipulate interest rates (and gold?) t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>474095</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://nutritionfacts.org/topics/inflammatory...</td>\n",
       "      <td>['preventing', 'crohns', 'disease', 'with', 'd...</td>\n",
       "      <td>inflammatory bowel disease</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>929765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.christianpost.com/news/if-free-tra...</td>\n",
       "      <td>['expand', 'collapse', 'dr', 'gordon', 'borono...</td>\n",
       "      <td>If Free Trade Is So Great, Why Are American Wo...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  domain_id  type_id  \\\n",
       "0  437287          1        1   \n",
       "1  929199          0        0   \n",
       "2  433367          1        1   \n",
       "3  474095          2        0   \n",
       "4  929765          0        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://beforeitsnews.com/financial-markets/201...   \n",
       "1  https://www.christianpost.com/news/birth-of-a-...   \n",
       "2  http://beforeitsnews.com/financial-markets/201...   \n",
       "3  https://nutritionfacts.org/topics/inflammatory...   \n",
       "4  https://www.christianpost.com/news/if-free-tra...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ['got', 'plans', 'saturday', 'of', 'readers', ...   \n",
       "1  ['the', 'views', 'expressed', 'by', 'the', 'au...   \n",
       "2  ['headline', 'bitcoin', 'blockchain', 'searche...   \n",
       "3  ['preventing', 'crohns', 'disease', 'with', 'd...   \n",
       "4  ['expand', 'collapse', 'dr', 'gordon', 'borono...   \n",
       "\n",
       "                                               title meta_description  \\\n",
       "0                                Got Plans Saturday?             None   \n",
       "1                          Birth of a Muslim Zionist             None   \n",
       "2  Fed to manipulate interest rates (and gold?) t...             None   \n",
       "3                         inflammatory bowel disease             None   \n",
       "4  If Free Trade Is So Great, Why Are American Wo...             None   \n",
       "\n",
       "   scraped_at  updated_at inserted_at  \n",
       "0  2018-01-25  2018-02-02  2018-02-02  \n",
       "1  2018-01-25  2018-02-02  2018-02-02  \n",
       "2  2018-01-25  2018-02-02  2018-02-02  \n",
       "3  2018-01-25  2018-02-02  2018-02-02  \n",
       "4  2018-01-25  2018-02-02  2018-02-02  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load dataset\n",
    "connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\")\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "filepath = '../Data_git_ignore/clean_csv/article_clean.csv' # 250 rows of FakeNewsCorpus\n",
    "s = 250                                            # desired sample size\n",
    "seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM fakenews.article\", connection)\n",
    "#df[\"content\"] = df[\"content\"].astype(str)\n",
    "# c*reate type_id\n",
    "#df['type_id'] = df.groupby(['type']).ngroup()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "\n",
    "df['content'] = df['content'].apply(' '.join)\n",
    "\n",
    "x = v.fit_transform(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x.toarray(), df[\"type_id\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laver modellen\n",
    "model = tf.keras.models.Sequential()\n",
    "# tilføjer et input på modellen\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# relu er default aktiverings funktion. Lav den om hvis resultatet ikke er godt nok\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "# jeg tilføjer 2 lag til netwærket. Dette er fordi det er en simpel opgave\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "\n",
    "#antallet (10) er antal output. Det er 10 tal i datasettet derfor skal der være et 10 tal\n",
    "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "# Dette er den mest komplexe del. adam er goto. Hvis der kun er 2 løsninger så brug binary_categorical_crossentropy eller binary_crossentropy i stedet for sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9600 samples\n",
      "Epoch 1/3\n",
      "9600/9600 [==============================] - 8s 824us/sample - loss: 0.4544 - accuracy: 0.8214\n",
      "Epoch 2/3\n",
      "9600/9600 [==============================] - 4s 432us/sample - loss: 0.0955 - accuracy: 0.9795\n",
      "Epoch 3/3\n",
      "9600/9600 [==============================] - 4s 425us/sample - loss: 0.0229 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fa1ed5a08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 5s 2ms/sample - loss: 0.0928 - accuracy: 0.9675\n",
      "0.09277646052340667 0.9675\n"
     ]
    }
   ],
   "source": [
    "# dette for for at trække om modellen er overfittet. val_loss og val_acc skal minde meget om det man får i fittet. \n",
    "#Det er ok at loss og acc er lidt højre på testen. De må ikke være fortæt eller for længt væk fra hinaden\n",
    "val_loss, val_acc = model.evaluate(X_test,y_test.values)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
