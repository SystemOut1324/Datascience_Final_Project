{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id  domain_id  type_id  \\\n22476   808451          1        0   \n9055     40330          1        0   \n3394    821607          1        0   \n5552     23931          1        0   \n80575   407069        117        3   \n...        ...        ...      ...   \n73349   317563        117        3   \n109259  913747        210        6   \n50057   407219         59        2   \n5192    777382          1        0   \n128037  752133        220        7   \n\n                                                      url  \\\n22476   http://beforeitsnews.com/forex/2014/08/gbpusd-...   \n9055    http://beforeitsnews.com/stories/category/diy....   \n3394    http://beforeitsnews.com/environment/2010/11/f...   \n5552    http://beforeitsnews.com/libertarian/2013/12/t...   \n80575   http://www.abovetopsecret.com/forum/thread1171...   \n...                                                   ...   \n73349   http://www.abovetopsecret.com/forum/thread7758...   \n109259  http://occupydemocrats.com/2016/09/16/trump-ju...   \n50057   http://investmentwatchblog.com/almost-all-deve...   \n5192    http://beforeitsnews.com/politics/2016/05/did-...   \n128037  http://www.ifyouonlynews.com/news/what-trump-j...   \n\n                                         content_tokenize  \\\n22476   ['gbpusd', 'daily', 'forecast', 'DATE', 'headl...   \n9055    ['NUM', 'by', 'show', 'tell', 'on', 'tuesday',...   \n3394    ['following', 'the', 'money', 'of', 'readers',...   \n5552    ['tampon', 'earrings', 'parody', 'of', 'reader...   \n80575   ['edit', 'on', 'DATE', 'by', 'tonycodes', 'bec...   \n...                                                   ...   \n73349   ['before', 'some', 'people', 'decide', 'to', '...   \n109259  ['mashshare', 'the', 'media', 'is', 'full', 'o...   \n50057   ['by', 'mark', 'angelides', 'the', 'idea', 'th...   \n5192    ['did', 'the', 'arabs', 'betray', 'palestine',...   \n128037  ['NUM', 'shares', 'shares', 'facebooktwitter',...   \n\n                                                  content  \\\n22476   gbpusd daily forecast DATE headline bitcoin bl...   \n9055            NUM by show tell on tuesday DATE NUM NUM    \n3394    following the money of readers think this stor...   \n5552    tampon earrings parody of readers think this s...   \n80575   edit on DATE by tonycodes because no reason gi...   \n...                                                   ...   \n73349   before some people decide to crap on this thre...   \n109259  mashshare the media is full of selfrighteous i...   \n50057    by mark angelides the idea that to ask voters...   \n5192    did the arabs betray palestine headline bitcoi...   \n128037   NUM shares shares facebooktwitter googlepinte...   \n\n                                                    title meta_description  \\\n22476                    GBPUSD Daily Forecast: August 22             None   \n9055                        Stories in the \"DIY\" category             None   \n3394                                 Following the money…             None   \n5552                               Tampon Earrings Parody             None   \n80575                     Help Mexico's Children!, page 1             None   \n...                                                   ...              ...   \n73349    Charleston County, SC and San Diego, CA., page 1             None   \n109259  Trump Just Tricked Gullible Media Into Promoti...             None   \n50057   Almost ALL Developed Nations Require Voter ID ...             None   \n5192                      Did the Arabs betray Palestine?             None   \n128037  What Trump Just Said About Breitbart News Will...             None   \n\n        scraped_at  updated_at inserted_at  \n22476   2018-01-25  2018-02-02  2018-02-02  \n9055    2018-01-25  2018-02-02  2018-02-02  \n3394    2018-01-25  2018-02-02  2018-02-02  \n5552    2018-01-25  2018-02-02  2018-02-02  \n80575   2018-01-25  2018-02-02  2018-02-02  \n...            ...         ...         ...  \n73349   2018-01-25  2018-02-02  2018-02-02  \n109259  2018-01-25  2018-02-02  2018-02-02  \n50057   2018-01-25  2018-02-02  2018-02-02  \n5192    2018-01-25  2018-02-02  2018-02-02  \n128037  2018-01-25  2018-02-02  2018-02-02  \n\n[171649 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>domain_id</th>\n      <th>type_id</th>\n      <th>url</th>\n      <th>content_tokenize</th>\n      <th>content</th>\n      <th>title</th>\n      <th>meta_description</th>\n      <th>scraped_at</th>\n      <th>updated_at</th>\n      <th>inserted_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22476</th>\n      <td>808451</td>\n      <td>1</td>\n      <td>0</td>\n      <td>http://beforeitsnews.com/forex/2014/08/gbpusd-...</td>\n      <td>['gbpusd', 'daily', 'forecast', 'DATE', 'headl...</td>\n      <td>gbpusd daily forecast DATE headline bitcoin bl...</td>\n      <td>GBPUSD Daily Forecast: August 22</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>9055</th>\n      <td>40330</td>\n      <td>1</td>\n      <td>0</td>\n      <td>http://beforeitsnews.com/stories/category/diy....</td>\n      <td>['NUM', 'by', 'show', 'tell', 'on', 'tuesday',...</td>\n      <td>NUM by show tell on tuesday DATE NUM NUM</td>\n      <td>Stories in the \"DIY\" category</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>3394</th>\n      <td>821607</td>\n      <td>1</td>\n      <td>0</td>\n      <td>http://beforeitsnews.com/environment/2010/11/f...</td>\n      <td>['following', 'the', 'money', 'of', 'readers',...</td>\n      <td>following the money of readers think this stor...</td>\n      <td>Following the money…</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>5552</th>\n      <td>23931</td>\n      <td>1</td>\n      <td>0</td>\n      <td>http://beforeitsnews.com/libertarian/2013/12/t...</td>\n      <td>['tampon', 'earrings', 'parody', 'of', 'reader...</td>\n      <td>tampon earrings parody of readers think this s...</td>\n      <td>Tampon Earrings Parody</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>80575</th>\n      <td>407069</td>\n      <td>117</td>\n      <td>3</td>\n      <td>http://www.abovetopsecret.com/forum/thread1171...</td>\n      <td>['edit', 'on', 'DATE', 'by', 'tonycodes', 'bec...</td>\n      <td>edit on DATE by tonycodes because no reason gi...</td>\n      <td>Help Mexico's Children!, page 1</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>73349</th>\n      <td>317563</td>\n      <td>117</td>\n      <td>3</td>\n      <td>http://www.abovetopsecret.com/forum/thread7758...</td>\n      <td>['before', 'some', 'people', 'decide', 'to', '...</td>\n      <td>before some people decide to crap on this thre...</td>\n      <td>Charleston County, SC and San Diego, CA., page 1</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>109259</th>\n      <td>913747</td>\n      <td>210</td>\n      <td>6</td>\n      <td>http://occupydemocrats.com/2016/09/16/trump-ju...</td>\n      <td>['mashshare', 'the', 'media', 'is', 'full', 'o...</td>\n      <td>mashshare the media is full of selfrighteous i...</td>\n      <td>Trump Just Tricked Gullible Media Into Promoti...</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>50057</th>\n      <td>407219</td>\n      <td>59</td>\n      <td>2</td>\n      <td>http://investmentwatchblog.com/almost-all-deve...</td>\n      <td>['by', 'mark', 'angelides', 'the', 'idea', 'th...</td>\n      <td>by mark angelides the idea that to ask voters...</td>\n      <td>Almost ALL Developed Nations Require Voter ID ...</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>777382</td>\n      <td>1</td>\n      <td>0</td>\n      <td>http://beforeitsnews.com/politics/2016/05/did-...</td>\n      <td>['did', 'the', 'arabs', 'betray', 'palestine',...</td>\n      <td>did the arabs betray palestine headline bitcoi...</td>\n      <td>Did the Arabs betray Palestine?</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n    <tr>\n      <th>128037</th>\n      <td>752133</td>\n      <td>220</td>\n      <td>7</td>\n      <td>http://www.ifyouonlynews.com/news/what-trump-j...</td>\n      <td>['NUM', 'shares', 'shares', 'facebooktwitter',...</td>\n      <td>NUM shares shares facebooktwitter googlepinte...</td>\n      <td>What Trump Just Said About Breitbart News Will...</td>\n      <td>None</td>\n      <td>2018-01-25</td>\n      <td>2018-02-02</td>\n      <td>2018-02-02</td>\n    </tr>\n  </tbody>\n</table>\n<p>171649 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "### load dataset\n",
    "connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"root\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database='postgres')\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random) \n",
    "filepath = '../Data_git_ignore/clean_csv/article_clean.csv' # 250 rows of FakeNewsCorpus\n",
    "f = 1.0                                            # desired frac\n",
    "seed = 1                                           # seed used by Pseudorandom number generator\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM fakenews.article\", connection).sample(frac=f, random_state=seed)\n",
    "#df[\"content\"] = df[\"content\"].astype(str)\n",
    "# c*reate type_id\n",
    "#df['type_id'] = df.groupby(['type']).ngroup()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# v = TfidfVectorizer()\n",
    "\n",
    "# #df['content'] = df['content'].apply(' '.join)\n",
    "\n",
    "# x = v.fit_transform(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x.toarray(), df[\"type_id\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        type_id                                            content\n22476         0  gbpusd daily forecast DATE headline bitcoin bl...\n9055          0          NUM by show tell on tuesday DATE NUM NUM \n3394          0  following the money of readers think this stor...\n5552          0  tampon earrings parody of readers think this s...\n80575         3  edit on DATE by tonycodes because no reason gi...\n...         ...                                                ...\n73349         3  before some people decide to crap on this thre...\n109259        6  mashshare the media is full of selfrighteous i...\n50057         2   by mark angelides the idea that to ask voters...\n5192          0  did the arabs betray palestine headline bitcoi...\n128037        7   NUM shares shares facebooktwitter googlepinte...\n\n[171649 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type_id</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22476</th>\n      <td>0</td>\n      <td>gbpusd daily forecast DATE headline bitcoin bl...</td>\n    </tr>\n    <tr>\n      <th>9055</th>\n      <td>0</td>\n      <td>NUM by show tell on tuesday DATE NUM NUM</td>\n    </tr>\n    <tr>\n      <th>3394</th>\n      <td>0</td>\n      <td>following the money of readers think this stor...</td>\n    </tr>\n    <tr>\n      <th>5552</th>\n      <td>0</td>\n      <td>tampon earrings parody of readers think this s...</td>\n    </tr>\n    <tr>\n      <th>80575</th>\n      <td>3</td>\n      <td>edit on DATE by tonycodes because no reason gi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>73349</th>\n      <td>3</td>\n      <td>before some people decide to crap on this thre...</td>\n    </tr>\n    <tr>\n      <th>109259</th>\n      <td>6</td>\n      <td>mashshare the media is full of selfrighteous i...</td>\n    </tr>\n    <tr>\n      <th>50057</th>\n      <td>2</td>\n      <td>by mark angelides the idea that to ask voters...</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>0</td>\n      <td>did the arabs betray palestine headline bitcoi...</td>\n    </tr>\n    <tr>\n      <th>128037</th>\n      <td>7</td>\n      <td>NUM shares shares facebooktwitter googlepinte...</td>\n    </tr>\n  </tbody>\n</table>\n<p>171649 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=> 0 (25000, 2) (17500, 2) (3750, 2) (3750, 2)\n=> 1 (7513, 2) (5259, 2) (1127, 2) (1127, 2)\n=> 2 (25000, 2) (17500, 2) (3750, 2) (3750, 2)\n=> 3 (25000, 2) (17500, 2) (3750, 2) (3750, 2)\n=> 4 (11468, 2) (8027, 2) (1721, 2) (1721, 2)\n=> 5 (3112, 2) (2178, 2) (467, 2) (467, 2)\n=> 6 (19334, 2) (13533, 2) (2901, 2) (2901, 2)\n=> 7 (25000, 2) (17500, 2) (3750, 2) (3750, 2)\n=> 8 (25000, 2) (17500, 2) (3750, 2) (3750, 2)\n=> 9 (5222, 2) (3655, 2) (784, 2) (784, 2)\n\n[Final split]\ntrain, test, validate ==> (120152, 2) (25747, 2) (25750, 2)\n"
    }
   ],
   "source": [
    "### SELECT TRAIN, TEST, VALIDATE ###\n",
    "\n",
    "# Select columns for dataset for furthere split\n",
    "X_columns = ['content'] # <- n number of columns\n",
    "y_column  = ['type_id'] # <- max one column\n",
    "\n",
    "# Select columns for dataframe\n",
    "df = df[y_columns+X_columns]\n",
    "\n",
    "\n",
    "# This can generate a dataset with random purmutation and a max size for each type(can be smaller if desired max is not possible)\n",
    "\n",
    "# max size for type\n",
    "max_size = 25000\n",
    "# traning_set ratio - splits data into traning=ratio,  test and validate=(1-ratio)/2 ex. train=80%, test=10%, validate=10%\n",
    "ratio=0.7\n",
    "\n",
    "\n",
    "# Labels to include - ['fake', 'satire', 'bias', 'conspiracy', 'state', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable'] - all labels\n",
    "\n",
    "# use_types = ['fake', 'satire', 'bias', 'conspiracy', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable'] # <- string labes\n",
    "use_types = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]                                                                                    # <- int labels\n",
    "\n",
    "# Random seed\n",
    "rnd = 1\n",
    "\n",
    "# initialize dataframes\n",
    "train    = pd.DataFrame(columns = df.columns)\n",
    "test     = pd.DataFrame(columns = df.columns)\n",
    "validate = pd.DataFrame(columns = df.columns)\n",
    "\n",
    "# add type to test splits\n",
    "for t in use_types:\n",
    "\n",
    "    # type size\n",
    "    type_size = df[y_columns[0]].loc[df[y_columns[0]] == t].value_counts().min()\n",
    "\n",
    "    if type_size > 0:\n",
    "        # set size of type slice\n",
    "        if type_size < max_size:\n",
    "            tmp = df.loc[df[y_columns[0]] == t].sample(n = type_size, random_state=rnd)\n",
    "        else:\n",
    "            tmp = df.loc[df[y_columns[0]] == t].sample(n = max_size, random_state=rnd)\n",
    "\n",
    "        # split current type\n",
    "        train_tmp, test_tmp, validate_tmp = np.split(tmp, [int(ratio * len(tmp)), int(((1-ratio)/2 + ratio) * len(tmp))])\n",
    "\n",
    "        # add tmp to dataframes\n",
    "        train    = pd.concat([train, train_tmp])\n",
    "        test     = pd.concat([test, test_tmp])\n",
    "        validate = pd.concat([validate, validate_tmp])\n",
    "    \n",
    "        # print split shape\n",
    "        print(\"=>\", t, tmp.shape, train_tmp.shape, validate_tmp.shape, validate_tmp.shape)\n",
    "    else:\n",
    "        print(\"\\n[Error]\", t, \"- not in dataset from [y_column] <-\", y_column)\n",
    "\n",
    "print(\"\\n[Final split]\\ntrain, test, validate ==>\", train.shape, test.shape, validate.shape)\n",
    "\n",
    "# Create X, y split for all sets\n",
    "X_train    = train[X_columns]\n",
    "y_train    = train[y_column]\n",
    "X_test     = test[X_columns]\n",
    "y_test     = test[y_column]\n",
    "X_validate = validate[X_columns]\n",
    "y_validate = validate[y_column]\n",
    "\n",
    "# Free memory\n",
    "del train\n",
    "del test\n",
    "del validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laver modellen\n",
    "model = tf.keras.models.Sequential()\n",
    "# tilføjer et input på modellen\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# relu er default aktiverings funktion. Lav den om hvis resultatet ikke er godt nok\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "# jeg tilføjer 2 lag til netwærket. Dette er fordi det er en simpel opgave\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "\n",
    "#antallet (10) er antal output. Det er 10 tal i datasettet derfor skal der være et 10 tal\n",
    "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "# Dette er den mest komplexe del. adam er goto. Hvis der kun er 2 løsninger så brug binary_categorical_crossentropy eller binary_crossentropy i stedet for sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-63ddeecf7cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m   \"\"\"\n\u001b[0;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 262\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 5s 2ms/sample - loss: 0.0928 - accuracy: 0.9675\n",
      "0.09277646052340667 0.9675\n"
     ]
    }
   ],
   "source": [
    "# dette for for at trække om modellen er overfittet. val_loss og val_acc skal minde meget om det man får i fittet. \n",
    "#Det er ok at loss og acc er lidt højre på testen. De må ikke være fortæt eller for længt væk fra hinaden\n",
    "val_loss, val_acc = model.evaluate(X_test,y_test.values)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('new': conda)",
   "language": "python",
   "name": "python37764bitnewcondae2b41800e1a24f049ef50ffcb90345e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}