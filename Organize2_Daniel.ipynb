{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries needed \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# libraries we might not need\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the following code\n",
    "to use the whole document you only need one file specified by filepath for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 16) <- size of dataframe \n",
      "\n",
      "CPU times: user 2.31 s, sys: 187 ms, total: 2.5 s\n",
      "Wall time: 2.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>content</th>\n",
       "      <th>authors</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>url</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "      <th>type</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48770</th>\n",
       "      <td>3660</td>\n",
       "      <td>World View: Both Greece and European Leaders S...</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>this morning s key headlines from generational...</td>\n",
       "      <td>John J. Xenakis</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://www.breitbart.com/national-security/201...</td>\n",
       "      <td>['Alexis Tsipras', 'Angela Merkel', 'Britain',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>World View: Both Greece and European Leaders S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tunisia, Generational Dynamics, Britain, Alexi...</td>\n",
       "      <td>political</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96003</th>\n",
       "      <td>7278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>daily app fix april &lt;number&gt; th &lt;number&gt; risk ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://beforeitsnews.com/science-and-technolog...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Daily App Fix April 20th 2013 â€“ RISK, Connect ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16182</th>\n",
       "      <td>4317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>consciousness and unified physics are the keys...</td>\n",
       "      <td>Waking Times</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>http://beforeitsnews.com/alternative/2016/07/c...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Consciousness and Unified Physics are the Keys...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89922</th>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>do something , anything headline : bitcoin blo...</td>\n",
       "      <td>Humble Student Of The Markets</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Do something, anything!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106668</th>\n",
       "      <td>5321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>from conservapedia transfer pricing is the set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://www.conservapedia.com/Transfer_Pricing</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>conservapedia.com</td>\n",
       "      <td>Transfer Pricing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bias</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                   meta_description  \\\n",
       "id                                                                      \n",
       "48770         3660  World View: Both Greece and European Leaders S...   \n",
       "96003         7278                                                NaN   \n",
       "16182         4317                                                NaN   \n",
       "89922         1932                                                NaN   \n",
       "106668        5321                                                NaN   \n",
       "\n",
       "                        updated_at  \\\n",
       "id                                   \n",
       "48770   2018-02-02 01:19:41.756664   \n",
       "96003   2018-02-02 01:19:41.756664   \n",
       "16182   2018-02-02 01:19:41.756664   \n",
       "89922   2018-02-02 01:19:41.756664   \n",
       "106668  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                  content  \\\n",
       "id                                                          \n",
       "48770   this morning s key headlines from generational...   \n",
       "96003   daily app fix april <number> th <number> risk ...   \n",
       "16182   consciousness and unified physics are the keys...   \n",
       "89922   do something , anything headline : bitcoin blo...   \n",
       "106668  from conservapedia transfer pricing is the set...   \n",
       "\n",
       "                              authors                  scraped_at  \\\n",
       "id                                                                  \n",
       "48770                 John J. Xenakis  2018-01-25 20:13:50.426130   \n",
       "96003                             NaN  2018-01-25 20:13:50.426130   \n",
       "16182                    Waking Times  2018-01-25 16:17:44.789555   \n",
       "89922   Humble Student Of The Markets  2018-01-25 20:13:50.426130   \n",
       "106668                            NaN  2018-01-25 20:13:50.426130   \n",
       "\n",
       "                                                      url  \\\n",
       "id                                                          \n",
       "48770   http://www.breitbart.com/national-security/201...   \n",
       "96003   http://beforeitsnews.com/science-and-technolog...   \n",
       "16182   http://beforeitsnews.com/alternative/2016/07/c...   \n",
       "89922   http://beforeitsnews.com/financial-markets/201...   \n",
       "106668      http://www.conservapedia.com/Transfer_Pricing   \n",
       "\n",
       "                                            meta_keywords  summary  \\\n",
       "id                                                                   \n",
       "48770   ['Alexis Tsipras', 'Angela Merkel', 'Britain',...      NaN   \n",
       "96003                                                ['']      NaN   \n",
       "16182                                                ['']      NaN   \n",
       "89922                                                ['']      NaN   \n",
       "106668                                               ['']      NaN   \n",
       "\n",
       "                   domain                                              title  \\\n",
       "id                                                                             \n",
       "48770       breitbart.com  World View: Both Greece and European Leaders S...   \n",
       "96003   beforeitsnews.com  Daily App Fix April 20th 2013 â€“ RISK, Connect ...   \n",
       "16182   beforeitsnews.com  Consciousness and Unified Physics are the Keys...   \n",
       "89922   beforeitsnews.com                            Do something, anything!   \n",
       "106668  conservapedia.com                                   Transfer Pricing   \n",
       "\n",
       "        keywords                                               tags  \\\n",
       "id                                                                    \n",
       "48770        NaN  Tunisia, Generational Dynamics, Britain, Alexi...   \n",
       "96003        NaN                                                NaN   \n",
       "16182        NaN                                                NaN   \n",
       "89922        NaN                                                NaN   \n",
       "106668       NaN                                                NaN   \n",
       "\n",
       "             type                 inserted_at  source  \n",
       "id                                                     \n",
       "48770   political  2018-02-02 01:19:41.756632     NaN  \n",
       "96003        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "16182        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "89922        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "106668       bias  2018-02-02 01:19:41.756632     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# imports a random sample of size s from csv-file as a pandas dataframe\n",
    "# pandas using python 3.X uses utf-8 encoding\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random)\n",
    "filepath = '/home/daniel/Downloads/clean-100k.csv'\n",
    "#filepath = 'news_sample.csv' # <- overwrite for setup\n",
    "s = 250                      # desired sample size(seems to have slack ie. not exact)\n",
    "seed = 1                     # seed used by Pseudorandom number generator\n",
    "\n",
    "# init dataframe with specified values\n",
    "df = pd.read_csv(filepath).sample(n=s, random_state=seed)\n",
    "\n",
    "# set dataframe index to article id - use df.to_csv('tmp.csv', index=True, header=True) as index=True writes index to csv with index_name\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "# visual output\n",
    "print(df.shape, '<- size of dataframe \\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data-tables: [name]-uniq / relational-tables: [name]_in\n",
    "creating csv-files for database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to save all csv-files\n",
    "path = 'Database_CSV_IN/'\n",
    "\n",
    "# create temporary dataframe and use article id as index \n",
    "out_df = pd.DataFrame({'id':df.index})\n",
    "out_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### types_uniq - data-table ###\n",
    "type_array = df.type.unique() # get array of unique types\n",
    "type_df = pd.DataFrame({'id': np.arange(type_array.size), 'name':type_array})\n",
    "\n",
    "# write file and free memory\n",
    "type_df.to_csv(path + 'type_clean.csv', index=False, header=True)\n",
    "#del type_array\n",
    "#del type_df # tmp delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "tags_series_of_lists = df.tags.dropna().str.split(', ') # -> ', ' not ','\n",
    "\n",
    "if not 'tags' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'tags', value = tags_series_of_lists)\n",
    "\n",
    "# flattern tags_series_of_lists to a set(ie. unique values only)\n",
    "tags_list = list(set([item for sublist in tags_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "tags_df = pd.DataFrame({'id': np.arange(len(tags_list)), 'name':tags_list})\n",
    "\n",
    "# write file and free memory\n",
    "tags_df.to_csv(path + 'tags_clean.csv', index=False, header=True)\n",
    "del tags_series_of_lists\n",
    "del tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and tags in a article (for all articles)\n",
    "articles_id_tags_name_pairs_df = out_df.tags.dropna().explode()\n",
    "\n",
    "# split tags_name and articles_id\n",
    "articles_id_array = articles_id_tags_name_pairs_df.index.to_numpy()\n",
    "tags_name_array = articles_id_tags_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap tags with tags_id]\n",
    "tags_name_as_key_df = tags_df.set_index('name')\n",
    "tags_dict = tags_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace tags with tag id\n",
    "tags_id = np.array([tags_dict[key] for key in tags_name_array])\n",
    "\n",
    "# create dataframe\n",
    "tags_in_df = pd.DataFrame(data=articles_id_array, index=tags_id, columns=['article_id'])\n",
    "tags_in_df.index.name='tags_id'\n",
    "\n",
    "# write file and free memory\n",
    "tags_in_df.to_csv(path + 'tags_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors-uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "authors_series_of_lists = df.authors.dropna().str.split(',') # -> ',' not ', '\n",
    "\n",
    "if not 'authors' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'authors', value = authors_series_of_lists)\n",
    "\n",
    "# flattern authors_series_of_lists to a set(ie. unique values only)\n",
    "authors_list = list(set([item for sublist in authors_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "authors_df = pd.DataFrame({'id': np.arange(len(authors_list)), 'name':authors_list})\n",
    "\n",
    "# write file and free memory\n",
    "authors_df.to_csv(path + 'authors_clean.csv', index=False, header=True)\n",
    "#del authors_series_of_lists\n",
    "#del authors_list\n",
    "#del authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and authors in a article (for all articles)\n",
    "articles_id_authors_name_pairs_df = out_df.authors.dropna().explode()\n",
    "\n",
    "# split authors_name and articles_id\n",
    "articles_id_array = articles_id_authors_name_pairs_df.index.to_numpy()\n",
    "authors_name_array = articles_id_authors_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap authors with authors_id]\n",
    "authors_name_as_key_df = authors_df.set_index('name')\n",
    "authors_dict = authors_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace authors with tag id\n",
    "authors_id = np.array([authors_dict[key] for key in authors_name_array])\n",
    "\n",
    "# create dataframe\n",
    "authors_in_df = pd.DataFrame(data=articles_id_array, index=authors_id, columns=['article_id'])\n",
    "authors_in_df.index.name='authors_id'\n",
    "\n",
    "# write file and free memory\n",
    "authors_in_df.to_csv(path + 'authors_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### domains-uniq - data-table ###\n",
    "domain_array = df.domain.unique() # get array of unique domains\n",
    "domain_df = pd.DataFrame({'id': np.arange(domain_array.size), 'name':domain_array})\n",
    "\n",
    "# write file and free memory\n",
    "domain_df.to_csv(path + 'domain_name_clean.csv', index=False, header=True)\n",
    "#del domain_array\n",
    "#del domain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_uniq - data-table ###\n",
    "\n",
    "# use regex to remove string-padding\n",
    "regex = r\" *['\\\"\\[\\]]+\"\n",
    "meta_keywords_series = df.meta_keywords.replace(to_replace=regex, value='', regex=True).str.split(',')\n",
    "#meta_keywords_series = meta_keywords_series.replace(r'', np.NaN)\n",
    "\n",
    "if not 'meta_keywords' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'meta_keywords', value = meta_keywords_series)\n",
    "\n",
    "# create array of unique\n",
    "meta_keywords_set = meta_keywords_series.explode().unique()\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_df = pd.DataFrame({'id': np.arange(len(meta_keywords_set)), 'name':meta_keywords_set})\n",
    "\n",
    "# write file and free memory\n",
    "meta_keywords_df.to_csv(path + 'meta_keywords_clean.csv', index=False, header=True)\n",
    "#del meta_keywords_series\n",
    "#del meta_keywords_set\n",
    "#del meta_keywords_list\n",
    "#del meta_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and meta_keywords in a article (for all articles)\n",
    "articles_id_meta_keywords_name_pairs_df = out_df.meta_keywords.dropna().explode()\n",
    "\n",
    "# split meta_keywords_name and articles_id\n",
    "articles_id_array = articles_id_meta_keywords_name_pairs_df.index.to_numpy()\n",
    "meta_keywords_name_array = articles_id_meta_keywords_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap meta_keywords with meta_keywords_id]\n",
    "meta_keywords_name_as_key_df = meta_keywords_df.set_index('name')\n",
    "meta_keywords_dict = meta_keywords_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace meta_keywords with tag id\n",
    "meta_keywords_id = np.array([meta_keywords_dict[key] for key in meta_keywords_name_array])\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_in_df = pd.DataFrame(data=articles_id_array, index=meta_keywords_id, columns=['article_id'])\n",
    "meta_keywords_in_df.index.name='meta_keywords_id'\n",
    "\n",
    "# write file and free memory\n",
    "meta_keywords_in_df.to_csv(path + 'meta_keywords_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### depricated - might be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row-function used for extracting article and uniq_[name] id\n",
    "def article_and_uniq_name_id(row, name_df):\n",
    "    # test for overlap(isin) between article_row and uniq_[name] and create np_array\n",
    "    tmp_df = name_df[name_df['name'].isin(row[0])] # MAYBE FASTER -> ONLY RETURN ONE COLUMN\n",
    "    tmp_np_array = tmp_df.values\n",
    "    \n",
    "    # create np_array with row_id for each uniq_[name]\n",
    "    row_id = np.full((np.size(tmp_np_array,0), 1), row.name)\n",
    "    \n",
    "    # combine\n",
    "    tmp_np_array = np.append(tmp_np_array, row_id, axis=1)\n",
    "\n",
    "    #print('>', tmp_df)\n",
    "    # change numer of columns to return [col_1, col2, ...]\n",
    "    return tmp_np_array[:, [0, -1]] # MAYBE NOT NEEDED IF CHAGED TO ONE ROW IE. FASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relational tags_in\n",
    "\n",
    "#tags_series_of_lists = out_df[['tags']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(tags_df, )) \n",
    "tags_series_of_lists = out_df[['tags']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(tags_df, )) \n",
    "\n",
    "# concat series into one np_array\n",
    "tags_in_ndarray = [element for list_ in tags_series_of_lists for element in list_]\n",
    "\n",
    "# create dataframe\n",
    "tags_in_df = pd.DataFrame(data = tags_in_ndarray, columns = ['tag_id', 'article_id'])\n",
    "\n",
    "# write file and free memory\n",
    "tags_in_df.to_csv(path + 'tags_in.csv', index=True, index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relational authors_in\n",
    "\n",
    "# series of np_arrays - \n",
    "authors_series_of_lists = out_df[['authors']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(authors_df, )) \n",
    "\n",
    "# concat series into one np_array\n",
    "authors_in_ndarray = [element for list_ in authors_series_of_lists for element in list_]\n",
    "\n",
    "# create dataframe\n",
    "authors_in_df = pd.DataFrame(data = authors_in_ndarray, columns = ['tag_id', 'article_id'])\n",
    "\n",
    "# write file and free memory\n",
    "authors_in_df.to_csv(path + 'authors_in.csv', index=True, index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148, 48770],\n",
       "       [57, 16182],\n",
       "       [139, 89922],\n",
       "       [109, 6149],\n",
       "       [120, 6149],\n",
       "       [189, 6149],\n",
       "       [102, 37524],\n",
       "       [33, 80069],\n",
       "       [81, 80069],\n",
       "       [97, 80069],\n",
       "       [13, 10733],\n",
       "       [35, 97547],\n",
       "       [157, 97547],\n",
       "       [3, 106395],\n",
       "       [10, 106395],\n",
       "       [17, 106395],\n",
       "       [49, 106395],\n",
       "       [77, 106395],\n",
       "       [80, 106395],\n",
       "       [86, 106395],\n",
       "       [105, 106395],\n",
       "       [132, 106395],\n",
       "       [164, 106395],\n",
       "       [206, 84637],\n",
       "       [124, 36062],\n",
       "       [64, 50587],\n",
       "       [73, 101062],\n",
       "       [87, 101062],\n",
       "       [127, 101062],\n",
       "       [162, 101062],\n",
       "       [193, 36200],\n",
       "       [79, 17232],\n",
       "       [186, 25174],\n",
       "       [89, 17821],\n",
       "       [187, 30390],\n",
       "       [87, 102852],\n",
       "       [127, 102852],\n",
       "       [162, 102852],\n",
       "       [0, 72915],\n",
       "       [11, 72915],\n",
       "       [31, 72915],\n",
       "       [83, 72915],\n",
       "       [87, 72915],\n",
       "       [127, 72915],\n",
       "       [162, 72915],\n",
       "       [197, 72915],\n",
       "       [207, 72915],\n",
       "       [214, 72915],\n",
       "       [22, 37257],\n",
       "       [36, 37257],\n",
       "       [44, 37257],\n",
       "       [61, 37257],\n",
       "       [62, 37257],\n",
       "       [88, 37257],\n",
       "       [121, 37257],\n",
       "       [149, 37257],\n",
       "       [170, 37257],\n",
       "       [192, 37257],\n",
       "       [78, 56230],\n",
       "       [106, 91090],\n",
       "       [107, 7807],\n",
       "       [43, 3457],\n",
       "       [189, 3457],\n",
       "       [131, 24123],\n",
       "       [23, 30393],\n",
       "       [3, 105754],\n",
       "       [10, 105754],\n",
       "       [17, 105754],\n",
       "       [49, 105754],\n",
       "       [77, 105754],\n",
       "       [80, 105754],\n",
       "       [86, 105754],\n",
       "       [105, 105754],\n",
       "       [132, 105754],\n",
       "       [164, 105754],\n",
       "       [21, 66473],\n",
       "       [159, 80887],\n",
       "       [95, 51900],\n",
       "       [151, 36458],\n",
       "       [1, 49440],\n",
       "       [74, 4554],\n",
       "       [120, 1422],\n",
       "       [189, 1422],\n",
       "       [194, 1422],\n",
       "       [85, 14526],\n",
       "       [169, 14526],\n",
       "       [120, 6384],\n",
       "       [161, 6384],\n",
       "       [189, 6384],\n",
       "       [195, 90719],\n",
       "       [3, 99726],\n",
       "       [10, 99726],\n",
       "       [17, 99726],\n",
       "       [49, 99726],\n",
       "       [77, 99726],\n",
       "       [80, 99726],\n",
       "       [86, 99726],\n",
       "       [105, 99726],\n",
       "       [132, 99726],\n",
       "       [164, 99726],\n",
       "       [98, 41706],\n",
       "       [26, 47576],\n",
       "       [182, 37020],\n",
       "       [59, 47375],\n",
       "       [134, 42117],\n",
       "       [178, 64242],\n",
       "       [8, 19649],\n",
       "       [3, 107595],\n",
       "       [10, 107595],\n",
       "       [17, 107595],\n",
       "       [49, 107595],\n",
       "       [77, 107595],\n",
       "       [80, 107595],\n",
       "       [86, 107595],\n",
       "       [105, 107595],\n",
       "       [132, 107595],\n",
       "       [164, 107595],\n",
       "       [43, 3885],\n",
       "       [189, 3885],\n",
       "       [185, 54550],\n",
       "       [203, 81584],\n",
       "       [68, 69387],\n",
       "       [122, 61364],\n",
       "       [174, 23013],\n",
       "       [9, 54591],\n",
       "       [103, 93853],\n",
       "       [19, 50327],\n",
       "       [158, 45142],\n",
       "       [28, 42937],\n",
       "       [60, 60506],\n",
       "       [140, 44013],\n",
       "       [104, 30373],\n",
       "       [178, 35212],\n",
       "       [154, 48069],\n",
       "       [57, 52140],\n",
       "       [147, 56020],\n",
       "       [123, 3472],\n",
       "       [20, 61718],\n",
       "       [42, 61718],\n",
       "       [56, 61718],\n",
       "       [67, 61718],\n",
       "       [113, 61718],\n",
       "       [145, 61718],\n",
       "       [165, 61718],\n",
       "       [198, 61718],\n",
       "       [135, 46731],\n",
       "       [96, 52591],\n",
       "       [119, 53940],\n",
       "       [110, 93070],\n",
       "       [20, 63028],\n",
       "       [30, 63028],\n",
       "       [56, 63028],\n",
       "       [63, 63028],\n",
       "       [67, 63028],\n",
       "       [145, 63028],\n",
       "       [160, 63028],\n",
       "       [165, 63028],\n",
       "       [198, 63028],\n",
       "       [178, 35530],\n",
       "       [20, 58039],\n",
       "       [56, 58039],\n",
       "       [67, 58039],\n",
       "       [113, 58039],\n",
       "       [115, 58039],\n",
       "       [145, 58039],\n",
       "       [198, 58039],\n",
       "       [38, 17513],\n",
       "       [117, 68220],\n",
       "       [208, 3019],\n",
       "       [50, 28625],\n",
       "       [141, 88149],\n",
       "       [163, 11104],\n",
       "       [128, 97703],\n",
       "       [29, 94993],\n",
       "       [176, 68727],\n",
       "       [14, 19963],\n",
       "       [3, 99756],\n",
       "       [10, 99756],\n",
       "       [17, 99756],\n",
       "       [49, 99756],\n",
       "       [77, 99756],\n",
       "       [80, 99756],\n",
       "       [86, 99756],\n",
       "       [105, 99756],\n",
       "       [132, 99756],\n",
       "       [164, 99756],\n",
       "       [32, 43671],\n",
       "       [65, 18041],\n",
       "       [69, 12998],\n",
       "       [153, 62067],\n",
       "       [41, 68618],\n",
       "       [37, 112197],\n",
       "       [45, 112197],\n",
       "       [209, 112197],\n",
       "       [82, 47026],\n",
       "       [120, 1433],\n",
       "       [189, 1433],\n",
       "       [194, 1433],\n",
       "       [87, 72155],\n",
       "       [91, 72155],\n",
       "       [127, 72155],\n",
       "       [162, 72155],\n",
       "       [193, 56174],\n",
       "       [39, 20537],\n",
       "       [20, 60041],\n",
       "       [54, 60041],\n",
       "       [56, 60041],\n",
       "       [67, 60041],\n",
       "       [145, 60041],\n",
       "       [165, 60041],\n",
       "       [166, 60041],\n",
       "       [198, 60041],\n",
       "       [27, 39188],\n",
       "       [142, 20681],\n",
       "       [120, 9572],\n",
       "       [125, 9572],\n",
       "       [189, 9572],\n",
       "       [3, 105208],\n",
       "       [10, 105208],\n",
       "       [17, 105208],\n",
       "       [49, 105208],\n",
       "       [77, 105208],\n",
       "       [80, 105208],\n",
       "       [86, 105208],\n",
       "       [105, 105208],\n",
       "       [132, 105208],\n",
       "       [164, 105208],\n",
       "       [7, 32356],\n",
       "       [12, 30487],\n",
       "       [204, 30487],\n",
       "       [51, 35893],\n",
       "       [48, 108570],\n",
       "       [87, 108570],\n",
       "       [127, 108570],\n",
       "       [162, 108570],\n",
       "       [171, 108570],\n",
       "       [210, 108570],\n",
       "       [43, 5355],\n",
       "       [189, 5355],\n",
       "       [90, 2125],\n",
       "       [101, 2125],\n",
       "       [173, 2125],\n",
       "       [211, 2125],\n",
       "       [123, 32111],\n",
       "       [34, 2564],\n",
       "       [123, 2564],\n",
       "       [70, 57535],\n",
       "       [111, 57535],\n",
       "       [136, 70711],\n",
       "       [46, 69452],\n",
       "       [87, 69452],\n",
       "       [127, 69452],\n",
       "       [162, 69452],\n",
       "       [3, 101480],\n",
       "       [10, 101480],\n",
       "       [17, 101480],\n",
       "       [49, 101480],\n",
       "       [77, 101480],\n",
       "       [80, 101480],\n",
       "       [86, 101480],\n",
       "       [105, 101480],\n",
       "       [132, 101480],\n",
       "       [164, 101480],\n",
       "       [92, 91299],\n",
       "       [24, 49301],\n",
       "       [2, 20003],\n",
       "       [16, 20003],\n",
       "       [47, 20003],\n",
       "       [129, 20003],\n",
       "       [133, 20003],\n",
       "       [155, 20003],\n",
       "       [175, 20003],\n",
       "       [179, 20003],\n",
       "       [184, 20003],\n",
       "       [205, 20003],\n",
       "       [3, 102909],\n",
       "       [10, 102909],\n",
       "       [17, 102909],\n",
       "       [49, 102909],\n",
       "       [77, 102909],\n",
       "       [80, 102909],\n",
       "       [86, 102909],\n",
       "       [105, 102909],\n",
       "       [132, 102909],\n",
       "       [164, 102909],\n",
       "       [52, 62271],\n",
       "       [213, 62271],\n",
       "       [152, 41727],\n",
       "       [177, 449],\n",
       "       [72, 52137],\n",
       "       [201, 52137],\n",
       "       [25, 43879],\n",
       "       [163, 13017],\n",
       "       [39, 20545],\n",
       "       [196, 59089],\n",
       "       [40, 75688],\n",
       "       [3, 110619],\n",
       "       [10, 110619],\n",
       "       [17, 110619],\n",
       "       [49, 110619],\n",
       "       [77, 110619],\n",
       "       [80, 110619],\n",
       "       [86, 110619],\n",
       "       [105, 110619],\n",
       "       [132, 110619],\n",
       "       [164, 110619],\n",
       "       [75, 103883],\n",
       "       [199, 103883],\n",
       "       [43, 3304],\n",
       "       [189, 3304],\n",
       "       [108, 15281],\n",
       "       [118, 58138],\n",
       "       [116, 20336],\n",
       "       [21, 74736],\n",
       "       [146, 85251],\n",
       "       [15, 52729],\n",
       "       [55, 74759],\n",
       "       [76, 74759],\n",
       "       [84, 74759],\n",
       "       [87, 74759],\n",
       "       [94, 74759],\n",
       "       [114, 74759],\n",
       "       [127, 74759],\n",
       "       [162, 74759],\n",
       "       [172, 74759],\n",
       "       [210, 74759],\n",
       "       [71, 100628],\n",
       "       [84, 100628],\n",
       "       [87, 100628],\n",
       "       [94, 100628],\n",
       "       [112, 100628],\n",
       "       [127, 100628],\n",
       "       [137, 100628],\n",
       "       [150, 100628],\n",
       "       [162, 100628],\n",
       "       [188, 100628],\n",
       "       [190, 25206],\n",
       "       [58, 78139],\n",
       "       [4, 101989],\n",
       "       [6, 101989],\n",
       "       [181, 101989],\n",
       "       [3, 87322],\n",
       "       [10, 87322],\n",
       "       [17, 87322],\n",
       "       [49, 87322],\n",
       "       [77, 87322],\n",
       "       [80, 87322],\n",
       "       [86, 87322],\n",
       "       [105, 87322],\n",
       "       [132, 87322],\n",
       "       [164, 87322],\n",
       "       [130, 42860],\n",
       "       [138, 30429],\n",
       "       [143, 30429],\n",
       "       [202, 30429],\n",
       "       [99, 57300],\n",
       "       [191, 57300],\n",
       "       [93, 27256],\n",
       "       [5, 46408],\n",
       "       [26, 38457],\n",
       "       [212, 40065],\n",
       "       [87, 107432],\n",
       "       [127, 107432],\n",
       "       [162, 107432],\n",
       "       [180, 11762],\n",
       "       [60, 59748],\n",
       "       [66, 41290],\n",
       "       [193, 50294],\n",
       "       [3, 87841],\n",
       "       [10, 87841],\n",
       "       [17, 87841],\n",
       "       [49, 87841],\n",
       "       [77, 87841],\n",
       "       [80, 87841],\n",
       "       [86, 87841],\n",
       "       [105, 87841],\n",
       "       [132, 87841],\n",
       "       [164, 87841],\n",
       "       [156, 41887],\n",
       "       [200, 65097],\n",
       "       [144, 10649],\n",
       "       [167, 26080],\n",
       "       [89, 69122],\n",
       "       [18, 80383],\n",
       "       [53, 80383],\n",
       "       [87, 80383],\n",
       "       [94, 80383],\n",
       "       [100, 80383],\n",
       "       [126, 80383],\n",
       "       [127, 80383],\n",
       "       [162, 80383],\n",
       "       [168, 80383],\n",
       "       [183, 80383],\n",
       "       [147, 38668]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_in_ndarray = np.array([element for list_ in authors_series_of_lists for element in list_])\n",
    "authors_in_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 1e-06 s\n",
       "File: <ipython-input-17-a1528040687e>\n",
       "Function: myFunc at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def myFunc():\n",
       "     2         1          1.0      1.0    100.0      return"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def myFunc():\n",
    "    return\n",
    "%lprun -f myFunc myFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
